#  attempt to replicate DCM as done in SPM
# this is mostly based on the distastrous attempt to copy the
# DCM version that is in SPM12 that is shared in GitHub
# at  https://github.com/tmdemelo/pydcm/tree/master
#

import numpy as np
import os
import matplotlib.pyplot as plt
import time
import nibabel as nib
import pandas as pd
import scipy
import scipy.sparse as sparse
import copy
import scipy.io
import scipy.linalg
import scipy.stats


def setup_and_run_dcm():
    resultsname = r'C:\Users\16135\PycharmProjects\pantheon\venv\test_functions\DCM_results.npy'

    TR = 3.0
    ROInames = ['C6RD', 'NRM', 'NGC', 'PAG']   # pick something for setup
    xY = []
    nR = len(ROInames)
    for rr in range(nR):
        # get voxel coordinates for each region - do this later, for now this is just simulation
        coords = [0,0,0]
        xY.append({'coords':coords, })

    tsize = 200
    X0 = 0  # no idea what this is, something about the voxel data

    load_test_data = True
    if load_test_data:
        savename = r'C:\stroman\spm12\dcm_test_data.mat'
        mat = scipy.io.loadmat(savename)
        tcdata = copy.deepcopy(mat['tcdata'])
        paradigm_base = copy.deepcopy(mat['paradigm_base'])
    else:
        tcdata = np.random.randn(tsize,nR)
        paradigm_base = np.random.randn(tsize,2)   # stimulus function

    stim_names = ['paradigm1']

    delays = np.tile(TR,(nR,1))/2  # equivalent to matlab function
    Q = []
    for nn in range(nR):
        q = np.zeros((nR,nR))
        q[nn,nn] = tsize
        Q += [q]

    # Q = np.ones((nR,1))*tsize

    Y = {'dt':TR, 'X0':X0, 'y':tcdata, 'name':ROInames, 'Q':Q}
    U = {'dt':TR,'u':paradigm_base, 'name':stim_names, 'idx':[1,0]}   # guessing at idx

    TE = 0.030

    options = {'nonlinear':0, 'two_state':0, 'stochastic':0, 'centre':0, 'nograph':1, 'maxnode':8, 'maxit':128, 'hidden':[], 'induced':0}

    # connectivity matrices
    a = np.array([[1,1,1,0],[1,1,0,1],[1,0,1,1],[0,1,1,1]])
    b0 = np.zeros((nR,nR))   # this example has two experimental factors that could modulate connectivity
    b1 = np.array([[1,0,1,0], [0,1,0,1],[1,0,1,0],[0,1,0,1]])
    b = np.concatenate((b0[:,:,np.newaxis],b1[:,:,np.newaxis]),axis=2)
    c = np.array([[1,0],[1,0],[1,0],[1,0]])
    d = np.zeros((nR,nR,0))

    P = {'xY':xY, 'n':nR, 'v':tsize, 'U':U, 'Y':Y, 'delays':delays, 'TE':TE, 'options':options,'a':a,'b':b,'c':c,'d':d}
    DCM = spm_dcm_estimate(P)

    results = {'DCM':DCM}
    np.save(resultsname, results)

    return DCM


def spm_dcm_estimate(P):
    """
    Estimates parameters of a DCM (bilinear or nonlinear) for fMRI data
    FORMAT [DCM] = spm_dcm_estimate(DCM)
      DCM - DCM structure or its filename

    Expects
    -------------------------------------------------------------------------
    DCM.a                              % switch on endogenous connections
    DCM.b                              % switch on bilinear modulations
    DCM.c                              % switch on exogenous connections
    DCM.d                              % switch on nonlinear modulations
    DCM.U                              % exogenous inputs
    DCM.Y.y                            % responses
    DCM.Y.X0                           % confounds
    DCM.Y.Q                            % array of precision components
    DCM.n                              % number of regions
    DCM.v                              % number of scans

    Options
    -------------------------------------------------------------------------
    DCM.options.two_state              % two regional populations (E and I)
    DCM.options.stochastic             % fluctuations on hidden states
    DCM.options.centre                 % mean-centre inputs
    DCM.options.nonlinear              % interactions among hidden states
    DCM.options.nograph                % graphical display
    DCM.options.induced                % switch for CSD data features
    DCM.options.P                      % starting estimates for parameters
    DCM.options.hidden                 % indices of hidden regions
    DCM.options.maxnodes               % maximum number of (effective) nodes
    DCM.options.maxit                  % maximum number of iterations
    DCM.options.hE                     % expected precision of the noise
    DCM.options.hC                     % variance of noise expectation

    Evaluates:
    -------------------------------------------------------------------------
    DCM.M                              % Model structure
    DCM.Ep                             % Condition means (parameter structure)
    DCM.Cp                             % Conditional covariances
    DCM.Vp                             % Conditional variances
    DCM.Pp                             % Conditional probabilities
    DCM.H1                             % 1st order hemodynamic kernels
    DCM.H2                             % 2nd order hemodynamic kernels
    DCM.K1                             % 1st order neuronal kernels
    DCM.K2                             % 2nd order neuronal kernels
    DCM.R                              % residuals
    DCM.y                              % predicted data
    DCM.T                              % Threshold for Posterior inference
    DCM.Ce                             % Error variance for each region
    DCM.F                              % Free-energy bound on log evidence
    DCM.ID                             % Data ID
    DCM.AIC                            % Akaike Information criterion
    DCM.BIC                            % Bayesian Information criterion

    _________________________________________________________________________
    Copyright (C) 2002-2012 Wellcome Trust Centre for Neuroimaging

    Karl Friston
    $Id: dcm_estimate.m 7479 2018-11-09 14:17:33Z peter $
    """

    # Load DCM structure
    # --------------------------------------------------------------------------
    # TODO? display progress and file selection dialog
    # - matlab spm opens a progress dialog
    # - if input is not specified, it also opens a file selection dialog
    #   via spm.select()

    # TODO? check if input is DCM object or filename?
    DCM = copy.deepcopy(P)
    # ------put in setup from other verion----------
    M = {}
    if not 'M' in DCM:
        DCM['M'] = M
    if not 'pdcm' in DCM['options']:
        DCM['options']['pdcm'] = 0
    if not 'two_state' in DCM['options']:
        DCM['options']['two_state'] = 0
    if not 'stochastic' in DCM['options']:
        DCM['options']['stochastic'] = 0
    if not 'nonlinear' in DCM['options']:
        DCM['options']['nonlinear'] = 0
    if not 'centre' in DCM['options']:
        DCM['options']['centre'] = 0
    if not 'hidden' in DCM['options']:
        DCM['options']['hidden'] = []  # matlab: []
    if not 'hE' in DCM['options']:
        DCM['options']['hE'] = 6
    if not 'hC' in DCM['options']:
        DCM['options']['hC'] = 1 / 128
    if not 'n' in DCM:
        DCM['n'] = np.size(DCM['a'], 1)
    if not 'v' in DCM:
        DCM['v'] = np.size(DCM['Y']['y'], 1)

    # TODO? check for DCM['options']['nograph'] and set M['nograph']?
    if not 'maxit' in DCM['options']:
        if 'nN' in DCM['options']:
            DCM['options']['maxit'] = DCM['options']['nN']
        # matlab: warning about nN deprecation
        elif DCM['options']['stochastic']:
            DCM['options']['maxit'] = 32
        else:
            DCM['options']['maxit'] = 128

    if 'Nmax' in DCM['M']:
        M['Nmax'] = DCM['M']['Nmax']
    else:
        M['Nmax'] = DCM['options']['maxit']

    # check max nodes
    # --------------------------------------------------------------------------
    if not 'maxnodes' in DCM['options']:
        if 'nmax' in DCM['options']:
            DCM['options']['maxnodes'] = DCM['options']['nmax']
        # matlab: warning about nmax deprecation
        else:
            DCM['options']['maxnodes'] = 8

    # analysis and options
    # --------------------------------------------------------------------------
    DCM['options']['induced'] = 0

    #----------------------------------------------------------------
    # spm_dcm_estimate(DCM)    - need to replicate this function

    U = DCM['U']	# exogenous inputs
    Y = DCM['Y']	# responses
    n = DCM['n']	# number of regions
    v = DCM['v']	# number of scans (time points)

    # detrend outputs (and inputs)
    # --------------------------------------------------------------------------
    Y['y'] = spm_detrend(Y['y'])
    if DCM['options']['centre']:
        U['u'] = spm_detrend(U['u'])

    # check scaling of Y (enforcing a maximum change of 4%
    # --------------------------------------------------------------------------
    scale = np.max(Y['y']) - np.min(Y['y'])
    scale = 4 / np.max([scale, 4])
    Y['y'] = Y['y'] * scale
    Y['scale'] = scale

    # check confounds (add constant if necessary)
    # --------------------------------------------------------------------------
    if not 'X0' in Y:
        Y['X0'] = np.ones((v, 1))
    if np.ndim(Y['X0']) < 2:  # matlab: if ~size(Y.X0, 2) ...
        Y['X0'] = np.ones((v, 1))

    # fMRI slice time sampling
    # --------------------------------------------------------------------------
    if 'delays' in DCM:
        M['delays'] = DCM['delays']
    else:
        M['delays'] = np.ones((n, 1))
    if 'TE' in DCM:
        M['TE'] = DCM['TE']

    # create priors
    # ==========================================================================

    # check DCM['d'] (for nonlinear DCMs)
    # --------------------------------------------------------------------------
    # TODO? better to explicitly check for nonlinear option?
    if ('d' in DCM) and (np.ndim(DCM['d']) > 2):
        DCM['options']['nonlinear'] = bool(DCM['d'].shape[2])
    else:
        DCM['d'] = np.zeros((n, n, 0))
        DCM['options']['nonlinear'] = 0

    # specify parameters for spm.integ_D (ensuring updates every second or so)
    # --------------------------------------------------------------------------
    if DCM['options']['nonlinear']:
        # M['IS'] = 'spm.integ_D'
        M['IS'] = 'spm_int'   # can't find spm_int_D yet ...
        M['nsteps'] = np.round(maximum(Y.dt, 1))
        # TODO: check if should start at 0 in python
        M['states'] = np.arange(1, n + 1)  # matlab: 1:n
    else:
        M['IS'] = 'spm_int'


    # check for endogenous DCMs, with no exogenous driving effects
    # --------------------------------------------------------------------------
    if (DCM['c'] is None) or (U['u'] is None):  # matlab: isempty
        DCM['c'] = np.zeros((n, 1))
        DCM['b'] = np.zeros((n, n, 1))
        U['u'] = np.zeros((v, 1))
        U['name'] = ['null']
    if (not np.any(spm_vec(U['u']))) or (not np.any(spm_vec(DCM['c']))):
        DCM['options']['stochastic'] = 1

    # priors (and initial states)
    # --------------------------------------------------------------------------
    if DCM['options']['pdcm']:
        [pE, pC, x] = pdcm_fmri_priors(DCM['a'], DCM['b'], DCM['c'], DCM['d'], DCM['options'])
        print('used pdcm_fmri_priors...')
    else:
        [pE, pC, x] = spm_dcm_fmri_priors(DCM['a'], DCM['b'], DCM['c'], DCM['d'], DCM['options'])
        print('used spm_dcm_fmri_priors...')
    msg = 'Using specified priors (any changes to DCM.a,b,c,d will be ignored)'

    # print('line 262 pE = {}'.format(pE))
    # print('line 262 DCM[a] = {}'.format(DCM['a']))

    # initial parameters
    if 'P' in DCM['options']:
        M['P'] = DCM['options']['P']
    # prior expectation
    if 'pE' in DCM['options']:
        pE = DCM['options']['pE']
        print(msg)
    # prior covariance
    if 'pC' in DCM['options']:
        pC = DCM['options']['pC']
        print(msg)

    # initial parameters
    if 'P' in DCM['M']:
        M['P'] = DCM['M']['P']
    # prior expectation
    if hasattr(DCM['M'], 'pE'):
        pE = DCM['M']['pE']
        print(msg)
    # prior covariance
    if hasattr(DCM['M'], 'pC'):
        pC = DCM['M']['pC']
        print(msg)

    # eigenvector constraints on pC for large models
    # --------------------------------------------------------------------------
    if n > DCM['options']['maxnodes']:
        # TODO: test this

        # remove confounds and find principal (nmax) modes
        # ----------------------------------------------------------------------
        # print('shape of Y[X0] is {}'.format(np.shape(Y['X0'])))
        # print('shape of pinv(Y[X0])is {}'.format(np.shape(np.linalg.pinv(Y['X0']))))
        # print('shape of Y[y] is {}'.format(np.shape(Y['y'])))

        y = Y['y'] - Y['X0'] @ (np.linalg.pinv(Y['X0']) @ Y['y'])
        V = spm_svd(y.T)
        V = V[:, np.arange(0, DCM['options']['maxnodes'])]

        # remove minor modes from priors on A
        # ----------------------------------------------------------------------
        j = np.arange(0, n * n)
        V = np.kron(V * V.T, V * V.T)
        pC[j, j] = V * pC[j, j] * V.T


    # eigenvector constraints on pC for large models
    # --------------------------------------------------------------------------
    if n > DCM['options']['maxnodes']:
        # TODO: test this

        # remove confounds and find principal (nmax) modes
        # ----------------------------------------------------------------------
        y = Y['y'] - Y['X0'] * (np.linalg.pinv(Y['X0']) * Y['y'])
        V = spm_svd(y.T)
        V = V[:, np.arange(0, DCM['options']['maxnodes'])]

        # remove minor modes from priors on A
        # ----------------------------------------------------------------------
        j = np.arange(0, n * n)
        V = np.kron(V * V.T, V * V.T)
        pC[j, j] = V * pC[j, j] * V.T


    # hyperpriors over precision - expectation and covariance
    # --------------------------------------------------------------------------
    hE = np.zeros((n, 1)) + DCM['options']['hE']  # matlab: sparse(n,1)
    hC = np.eye(n) * DCM['options']['hC']  # matlab: speye(n,n)
    i = DCM['options']['hidden']
    # if `i' is an empty list, indexing with it doesn't return or set anything
    # TODO: make it more explicit?
    hE[i] = -4
    hC[i, i] = np.exp(-16)

    # complete model specification
    # --------------------------------------------------------------------------
    if DCM['options']['pdcm']:
        M['f'] = 'fx_fmri_pdcm'  # equations of motion for p-dcm
    else:
        M['f'] = 'spm_fx_fmri'  # equations of motion
    M['g'] = 'spm_gx_fmri'  # observation equation
    M['x'] = x  # initial condition (states)
    M['pE'] = pE  # prior expectation (parameters)
    M['pC'] = pC  # prior covariance  (parameters)
    M['hE'] = hE  # prior expectation (precisions)
    M['hC'] = hC  # prior covariance  (precisions)
    M['m'] = U['u'].shape[1]
    M['n'] = np.size(x)
    M['l'] = x.shape[0]
    M['N'] = 64
    M['dt'] = 32 / M['N']
    M['ns'] = v

    # nonlinear system identification (nlsi)
    # ==========================================================================
    if not DCM['options']['stochastic']:
        # nonlinear system identification (Variational EM) - deterministic DCM
        # ----------------------------------------------------------------------
        Ep, Cp, Eh, F, *_ = spm_nlsi_GN(M, U, Y)

        # predicted responses (y) and residuals (R)
        # ----------------------------------------------------------------------
        y = eval(M['IS'])(Ep, M, U)
        R = Y['y'] - y
        R = R - Y['X0'] @ spm_inv(Y['X0'].T @ Y['X0']) @ (Y['X0'].T @ R)
        Ce = np.exp(-Eh)

    else:
        raise Exception('Stochastic DCM not implemented.')


    # Bilinear representation and first-order hemodynamic kernel
    # --------------------------------------------------------------------------
    M0, M1, L1, L2 = spm_bireduce(M, Ep, nout=4)
    H0, H1 = spm_kernels(M0, M1, L1, L2, M['N'], M['dt'], nout=2)

    # and neuronal kernels
    # --------------------------------------------------------------------------
    # matlab: L = sparse(1:n,(1:n) + 1,1,n,length(M0))
    L = np.zeros((n, max(M0.shape)))
    L[np.arange(n), np.arange(n) + 1] = 1
    K0, K1 = spm_kernels(M0, M1, L, M['N'], M['dt'], nout=2)

    # Bayesian inference and variance {threshold: prior mean plus T = 0}
    # --------------------------------------------------------------------------
    T = dense(spm_vec(pE))  # matlab: full(spm_vec(pE)
    # matlab: sw = warning('off','SPM:negativeVariance')
    with np.errstate(divide='ignore', invalid='ignore'):
        Pp = spm_unvec(1 - spm_Ncdf(T, np.abs(spm_vec(Ep)), np.diag(Cp).reshape(-1, 1)), Ep)
    Vp = spm_unvec(dense(np.diag(Cp)), Ep)  # matlab: full(diag(Cp))

    # Store parameter estimates
    # --------------------------------------------------------------------------
    DCM['M'] = M
    DCM['Y'] = Y
    DCM['U'] = U
    DCM['Ce'] = Ce
    DCM['Ep'] = Ep
    DCM['Cp'] = Cp
    DCM['Pp'] = Pp
    DCM['Vp'] = Vp
    DCM['H1'] = H1
    DCM['K1'] = K1
    DCM['R'] = R
    DCM['y'] = y
    DCM['T'] = 0

    # Data ID and log-evidence
    # ==========================================================================
    if 'FS' in M:
        # TODO: test/guess what could go wrong here
        try:
            ID = spm_data_id(eval(M['FS'])(Y['y'], M))
        except:
            ID = spm_data_id(eval(M['FS'])(Y['y']))
    else:
        ID = spm_data_id(Y['y'])

    # Save approximations to model evidence: negative free energy, AIC, BIC
    # --------------------------------------------------------------------------
    evidence = spm_dcm_evidence(DCM)
    DCM['F'] = F
    DCM['ID'] = ID
    DCM['AIC'] = evidence['aic_overall']
    DCM['BIC'] = evidence['bic_overall']

    # Save SPM version and revision number of code used
    # --------------------------------------------------------------------------
    # hardcoded for now
    DCM['version'] = {}
    DCM['version']['SPM'] = {}
    DCM['version']['DCM'] = {}
    DCM['version']['SPM']['version'] = 'SPM12'  # matlab: spm('Ver')
    DCM['version']['SPM']['revision'] = '7487'  # matlab: spm('Ver'), second output
    DCM['version']['DCM']['version'] = 'DCM12.5'  # matlab: spm.dcm_ui('Version')
    DCM['version']['DCM']['revision'] = '$Rev: 7479 $'  # likely relevant for Friston's team

    # Save DCM
    # --------------------------------------------------------------------------
    # not for now
    # matlab: check if P is not struct, so it should be a filename or file handle
    # matlab: save(P,'DCM','F','Ep','Cp', spm.get_defaults('mat.format'))

    return DCM

#------------------------------------------------------------------------
#------------------------------------------------------------------------
#------------------------------------------------------------------------
#------------------------------------------------------------------------
#
#
# # if d has 3 dimensions then a nonlinear dcm is specified
# # slice timing delays
# #  IS = 'spm_int' means this is not setting up a nonlinear DCM
# M = {'delays':np.ones((nR,1)),'TE':TE, 'IS':'spm_int'}
#
#
# # priors and initial states
# # spm_dcm_fmri_priors
# pE, C, x, pC = spm_dcm_fmri_priors(a,b,c,d,options)
#
# # % hyperpriors over precision - expectation and covariance
# # %--------------------------------------------------------------------------
# # hE      = scipy.sparse.csr_matrix((n,1), dtype=float).toarray() +options['hE']
# hE      = np.zeros((n,1)) +options['hE']
# hC      = np.eye(n)  * options['hC']
# ii       = options['hidden']
# hE[ii]   = -4
# hC[ii,ii] = np.exp(-16)
#
#
#
# # % complete model specification
# # %--------------------------------------------------------------------------
# if np.ndim(U['u']) < 2:
# 	m = 0
# else:
# 	m = np.shape(U['u'])[1]
#
# addM = {'f':'spm_fx_fmri', 'g':'spm_gx_fmri', 'x':x, 'pE':pE, 'pC':pC, 'hE':hE, 'hC':hC,
# 	 'm':m, 'n':np.prod(x.shape), 'l':np.shape(x)[0], 'N':64, 'dt':0.5, 'ns':v}
# M.update(addM)
#
#
#
# # % nonlinear system identification (nlsi)
# # %==========================================================================
# if not options['stochastic']:
#     # % nonlinear system identification (Variational EM) - deterministic DCM
#     # %----------------------------------------------------------------------
#     # [Ep,Cp,Eh,F] = spm_nlsi_GN(M,U,Y);
#     #
#     # % predicted responses (y) and residuals (R)
#     # %----------------------------------------------------------------------
#     # y      = feval(M.IS,Ep,M,U);
#     # R      = Y.y - y;
#     # R      = R - Y.X0*spm_inv(Y.X0'*Y.X0)*(Y.X0'*R);
#     # Ce     = exp(-Eh);
#
# 	Ep, Cp, Eh, F = spm_nlsi_GN(M, U, Y)


def spm_vec(X):
	vtype = type(X)

	# type can be int, float, tuple, list, dict, str, np.ndarray
	if isinstance(X,int) | isinstance(X,float) | isinstance(X,np.ndarray):
		vX = np.array(X).flatten()
	else:
		if isinstance(X,bool):
			vX = np.array(X).flatten()

	if isinstance(X, dict):
		vX = []
		f = X.keys()
		for nn, fname in enumerate(f):
			if nn == 0:
				vX = X[fname].flatten()
			else:
				vX = np.concatenate((vX, X[fname].flatten()), axis=0)

	return vX



#
# def spm_dcm_fmri_priors(A,B,C,D,options):
# 	# converted from spm
# 	# % Returns the priors for a two-state DCM for fMRI.
# 	# % FORMAT:[pE,pC,x,vC] = spm_dcm_fmri_priors(A,B,C,D,options)
# 	# %
# 	# %   options.two_state:  (0 or 1) one or two states per region
# 	# %   options.stochastic: (0 or 1) exogenous or endogenous fluctuations
# 	# %   options.precision:           log precision on connection rates
# 	# %
# 	# % INPUT:
# 	# %    A,B,C,D - constraints on connections (1 - present, 0 - absent)
# 	# %
# 	# % OUTPUT:
# 	# %    pE     - prior expectations (connections and hemodynamic)
# 	# %    pC     - prior covariances  (connections and hemodynamic)
# 	# %    x      - prior (initial) states
# 	# %    vC     - prior variances    (in struct form)
# 	# %__________________________________________________________________________
# 	n = np.shape(A)[0]
#
# 	if options['two_state']:
# 		# x = scipy.sparse.csr_matrix((n,6), dtype=float).toarray()
# 		x = np.zeros((n,6))
# 		tempA = A - np.diag(np.diag(A))
# 		A = (tempA > 0)
#
# 		try:
# 			pA = np.exp(options['precision'])
# 		except:
# 			pA = 16
#
# 		# prior expectations and covariances
# 		peA = (A + np.eye(n))*32 -32
# 		peB = B*0
# 		peC = C*0
# 		peD = D*0
#
# 		# prior covariances
# 		if np.ndim(A) > 2:
# 			for ii in range(np.shape(A)[2]):
# 				pcA[:,:,ii] = A[:,:,ii]/pA + np.eye(n)/pA
# 		else:
# 			pcA = A/pA + np.eye(n)/pA
#
# 		pcB = B/4
# 		pcC = C*4
# 		pcD = D/4
#
# 		# excitatory proportion
# 		if options['backwards']:
# 			peA[:,:,1] = A*0
# 			pcA[:,:,1] = A/pA
#
# 	else:
# 		# one hidden state per node
# 		# x = scipy.sparse.csr_matrix((n,5), dtype=float).toarray()
# 		x = np.zeros((n,5))
#
# 		# precision of connections
# 		try:
# 			pA = np.exp(options['precision'])
# 		except:
# 			pA = 64
#
# 		try:
# 			dA = np.exp(options['decay'])
# 		except:
# 			dA = 1
#
# 		# prior expectations
# 		if np.ndim(A) == 1:
# 			A = (A > 0)
# 			peA = (A-1)*dA
# 		else:
# 			tempA = A - np.diag(np.diag(A))
# 			A = (tempA > 0)
# 			peA = A/128
#
# 		peB = B*0
# 		peC = C*0
# 		peD = D*0
#
# 		# prior covariances
# 		if np.ndim(A) == 1:
# 			pcA = copy.deepcopy(A)
# 		else:
# 			if np.ndim(A) > 2:
# 				for ii in range(np.shape(A)[2]):
# 					pcA[:,:,ii] = A[:,:,ii]/pA + np.eye(n)/pA
# 			else:
# 				pcA = A/pA + np.eye(n)/pA
# 		pcB = B
# 		pcC = C
# 		pcD = D
#
# 	pE = {'A':peA, 'B':peB, 'C':peC, 'D':peD}
# 	pC = {'A':pcA, 'B':pcB, 'C':pcC, 'D':pcD}
#
# 	# add hemodynamic priors
# 	pE['transit'] = np.zeros((n,1))
# 	pC['transit'] = np.zeros((n,1)) + 1/256
#
# 	pE['decay'] = np.zeros((1,1))
# 	pC['decay'] = np.zeros((1,1)) + 1/256
#
# 	pE['epsilon'] = np.zeros((1,1))
# 	pC['epsilon'] = np.zeros((1,1))+ 1/256
#
# 	if options['induced']:
# 		pE['A'] = np.zeros((2,1))
# 		pC['A'] = np.zeros((2,1)) + 1/64
#
# 		pE['B'] = np.zeros((2,1))
# 		pC['B'] = np.zeros((2,1)) + 1/64
#
# 		pE['C'] = np.zeros((1,n))
# 		pC['C'] = np.zeros((1,n)) + 1/64
#
#
# 	# prior covariance matrix
# 	# C = np.diag(spm_vec(pC))
# 	# vectorize this here instead ...
# 	# vX = []
# 	# f = pC.keys()
# 	# for nn, fname in enumerate(f):
# 	# 	if nn == 0:
# 	# 		vX = pC[fname].flatten()
# 	# 	else:
# 	# 		vX = np.concatenate((vX,pC[fname].flatten()),axis=0)
#
# 	vX = spm_vec(pC)
# 	C = np.diag(vX)
#
# 	return pE, C, x, pC

#
# def spm_nlsi_GN(M, U, Y):
# 	# function to call is named in M['FS']
# 	# this version is reduced from the matlab version
#
# 	M['IS'] = 'spm_int'
# 	y = Y['y']
# 	# convert 'IS', 'f', 'g', and 'h' to function calls
# 	ns = np.shape(y)[0]
# 	ny = np.prod(np.shape(y))
# 	nr = ny/ns
# 	M['ns'] = ns
#
# 	dt = Y['dt']
# 	Q = Y['Q']
# 	try:
# 		nh = len(Q)
# 	except:
# 		nh = 1
# 	nq = ny/nh
#
# 	pC = M['pC']
# 	pE = M['pE']
#
# 	# confounds if specified
# 	try:
# 		nb = np.shape(Y['X0'])[0]
# 		nx = ny/nb
# 		dfdu = np.kron(np.eye(nx),Y['X0'])
# 	except:
# 		dfdu = np.zeros((ny,0))
#
#
# 	# hyperpriors - expectation
# 	try:
# 		hE = M['hE']
# 		if len(hE) != nh:
# 			hE += np.zeros((nh,1))
# 	except:
# 		hE = np.zeros((nh,1)) - np.log(np.var(spm_vec(y))) + 4
# 	h = hE
#
# 	# hyperpriors - covariance
# 	try:
# 		ihC = np.linalg.inv(M['hC'])
# 		if np.shape(ihC)[0] != nh:
# 			ihC = ihC * np.eye(nh)
# 	except:
# 		ihC = np.eye(nh) * np.exp(4)
#
#
# 	# unpack covariance
# 	pC = np.diag(spm_vec(pC))
#
# 	# dimension reduction of parameter space
# 	Us,Ss,Vs = np.linalg.svd(pC)
# 	V = copy.deepcopy(Us)
# 	nu = np.shape(dfdu)[1]
# 	np_var = np.shape(V)[1]
# 	ip = np.array(range(np_var))
# 	iu = np.array(range(nu)) + np_var
#
# 	# second-order moments (in reduced space)
# 	pC = V.T @ pC @ V
# 	uC = np.eye(nu)/1e-8
# 	# ipC = np.linalg.inv(np.concatenate((pC, np.diag(uC)), axis = 0))
# 	ipC = np.linalg.inv(pC)   # this wil probably work in most cases
#
# # % initialize conditional density
# # %--------------------------------------------------------------------------
# 	Eu  = np.linalg.inv(dfdu)*spm_vec(y)
# 	p   = np.concatenate((V.T @ (spm_vec(M['P']) - spm_vec(M['pE'])), Eu),axis=0)
# 	Ep   = spm_unvec(spm_vec(pE) + V @ p[ip], pE)
#
#
# 	return Ep, Cp, Eh, F



def spm_detrend(x,p = 0):
# % Polynomial detrending over columns
# % FORMAT y = spm_detrend(x,p)
# % x   - data matrix
# % p   - order of polynomial [default: 0]
# %
# % y   - detrended data matrix
# %__________________________________________________________________________
# %
# % spm_detrend removes linear and nonlinear trends from column-wise data
# % matrices.
# %__________________________________________________________________________
# % Copyright (C) 2008 Wellcome Trust Centre for Neuroimaging
#
# % Karl Friston
# % $Id: spm_detrend.m 7271 2018-03-04 13:11:54Z karl $
#
    if x.ndim == 1:
        x = x[:,np.newaxis]

    m,n = np.shape(x)
    if (not m) | (not n):
        y = []
        return y

    # % centre columns
    # %--------------------------------------------------------------------------
    if not p:
        y = x - np.ones((m,1))*np.mean(x)
        return y

    # % polynomial adjustment
    # %--------------------------------------------------------------------------
    G = np.zeros((m,p + 1))
    for ii in range(p+1):
        d = (np.array(range(m))**ii).astype(float)
        # d -= np.mean(d)
        G[:,ii] = d
    b = np.linalg.inv(G.T @ G) @ G.T @ x
    fit = G @ b
    y  = x - fit
    return y


def spm_int(P, M, U):
    """
    integrates a MIMO bilinear system dx/dt = f(x,u) = A*x + B*x*u + Cu + D;
    FORMAT [y] = spm_int(P,M,U)
    P   - model parameters
    M   - model structure
      M.delays - sampling delays (s); a vector with a delay for each output

    U   - input structure or matrix

    y   - response y = g(x,u,P)
    _________________________________________________________________________
    Integrates the bilinear approximation to the MIMO system described by

       dx/dt = f(x,u,P) = A*x + u*B*x + C*u + D
       y     = g(x,u,P) = L*x;

    at v = M.ns is the number of samples [default v = size(U.u,1)]

    spm_int will also handle static observation models by evaluating
    g(x,u,P).  It will also handle timing delays if specified in M.delays

    -------------------------------------------------------------------------

    SPM solvers or integrators

    spm_int_ode:  uses ode45 (or ode113) which are one and multi-step solvers
    respectively.  They can be used for any ODEs, where the Jacobian is
    unknown or difficult to compute; however, they may be slow.

    spm_int_J: uses an explicit Jacobian-based update scheme that preserves
    nonlinearities in the ODE: dx = (expm(dt * J) - I) * inv(J) * f.  If the
    equations of motion return J = df/dx, it will be used; otherwise it is
    evaluated numerically, using spm_diff at each time point.  This scheme is
    infallible but potentially slow, if the Jacobian is not available (calls
    spm_dx).

    spm_int_E: As for spm_int_J but uses the eigensystem of J(x(0)) to eschew
    matrix exponentials and inversion during the integration. It is probably
    the best compromise, if the Jacobian is not available explicitly.

    spm_int_B: As for spm_int_J but uses a first-order approximation to J
    based on J(x(t)) = J(x(0)) + dJdx*x(t).

    spm_int_L: As for spm_int_B but uses J(x(0)).

    spm_int_U: like spm_int_J but only evaluates J when the input changes.
    This can be useful if input changes are sparse (e.g., boxcar functions).
    It is used primarily for integrating EEG models

    spm_int: Fast integrator that uses a bilinear approximation to the
    Jacobian evaluated using spm_bireduce. This routine will also allow for
    sparse sampling of the solution and delays in observing outputs. It is
    used primarily for integrating fMRI models (see also spm_int_D)
    _________________________________________________________________________
    Copyright (C) 2008 Wellcome Trust Centre for Neuroimaging

    Karl Friston
    $Id: spm_int.m 6856 2016-08-10 17:55:05Z karl $
    """

    # convert U to U['u'] if necessary
    # --------------------------------------------------------------------------
    if not isinstance(U, dict):
        u = {}
        u['u'] = U
        U = u
    if 'dt' in U:
        dt = U['dt']
    else:
        U['dt'] = 1
        dt = U['dt']

    # number of times to sample (v) and number of microtime bins (u)
    # --------------------------------------------------------------------------
    u = np.shape(U['u'])[0]
    if 'ns' in M:
        v = M['ns']
    else:
        v = u

    # get expansion point
    # --------------------------------------------------------------------------
    x = spm_vec(1, M['x'])  # matlab: [1; spm_vec(M.x)]

    # add [0] states if not specified
    # --------------------------------------------------------------------------
    try:
        M['f'] = spm_funcheck(M['f'])
    except:
        M['f'] = lambda x, u, P, M: zeros((0, 1))  # sparse(0,1)
        M['x'] = zeros((0, 0))  # sparse(0,0)

    # output nonlinearity, if specified
    # --------------------------------------------------------------------------
    try:
        g = spm_funcheck(M['g'])
    except:
        g = lambda x, u, P, M: x
        M['g'] = g

    # Bilinear approximation (1st order)
    # --------------------------------------------------------------------------
    # print('line 886:  P = {}'.format(P))
    M0, M1 = spm_bireduce(M, P)
    m = len(M1)  # m inputs  # matlab: length

    if 'delays' in M:
        D = np.maximum(np.round(M['delays'] / U['dt']), 1)
    else:
        D = np.ones((M['l'], 1)) @ np.round(u / v)

    # Evaluation times (t) and indicator array for inputs (su) and output (sy)
    # ==========================================================================

    # get times that the input changes
    # --------------------------------------------------------------------------
    # matlab: i = [1 (1 + find(any(diff(U.u),2))')]
    i = np.hstack((0, 1 + np.nonzero(np.any(np.diff(U['u'], axis=0), axis=1))[0]))
    su = np.zeros((1, u), dtype=bool)  # matlab: sparse(1,i,1,1,u)
    su.ravel()[i] = 1

    # get times that the response is sampled
    # --------------------------------------------------------------------------
    s = np.ceil(np.arange(v) * u / v).astype(int)
    sy = np.zeros((M['l'], u), dtype=int)
    for j in range(M['l']):
        i = s + D.ravel()[j].astype(int) - 1
        # matlab: sy[j,:] = sparse(1,i,1:v,1,u)
        # TODO: make this efficient/streamline it/test
        sy_ji = np.zeros(u)
        sy_ji[i] = np.arange(1, v + 1)
        sy[j, :] = sy_ji
        # sy[j, i] = arange(v) + 1

    # time in seconds
    # --------------------------------------------------------------------------
    t = np.nonzero(su.ravel() | np.any(sy, 0))[0]
    su = dense(su[:, t])  # matlab: full(su(:,t))
    sy = dense(sy[:, t])  # matlab: full(sy(:,t))
    dt = np.hstack((np.diff(t), 0)) * U['dt']

    # Integrate
    # --------------------------------------------------------------------------

    y = np.zeros((M['l'], v))
    J = copy.copy(M0)
    U['u'] = dense(U['u'])  # matlab: U.u = full(U.u)
    for i in range(np.size(t)):

        # input dependent changes in Jacobian
        # ----------------------------------------------------------------------
        if su[:, i]:
            u = U['u'][t[i], :]
            J = copy.copy(M0)
            for j in range(m):
                J = J + u[j] * M1[j]

        # output sampled
        # ----------------------------------------------------------------------
        if np.any(sy[:, i]):
            q = spm_unvec(x[1:], M['x'])
            q = spm_vec(g(q, u, P, M))
            j = np.nonzero(sy[:, i])[0]
            s = sy[j[0], i] - 1
            y[j, s] = q.ravel()[j]

        # matlab: x = spm_expm(J*dt[i],x)
        # x = scipy.linalg.expm(J * dt[i]) @ x
        x = spm_expm(J * dt[i], x)

        # check for convergence
        # ----------------------------------------------------------------------
        # norm(x, 1) is kinda slow here
        if norm1(x) > 1e6:
            break

    return y.T

def norm1(x):
    return np.max(np.sum(np.abs(x), axis=0))

def spm_vec(X, *args):
    """
    Vectorise a numeric, cell or structure array - a compiled routine
    FORMAT [vX] = spm_vec(X)
    X  - numeric, cell or stucture array[s]
    vX - vec(X)

    See spm_unvec
    _________________________________________________________________________

    e.g.:
    spm_vec({eye(2) 3}) = [1 0 0 1 3]'
    _________________________________________________________________________
    Copyright (C) 2005-2013 Wellcome Trust Centre for Neuroimaging

    Karl Friston
    $Id: spm_vec.m 6110 2014-07-21 09:36:13Z karl $


    error('spm_vec.c not compiled - see Makefile')
    """

    # initialise X and vX
    # --------------------------------------------------------------------------
    vX = np.empty(shape=(0, 1))
    if len(args) > 0:
        X = [X, args]

    # vectorize numeric arrays
    if isnumericarray(X):
        # using order='F' is an order of magnitude slower
        # but it makes things equivalent to matlab
        vX = np.atleast_2d(X.ravel(order='F')).T
        # to use the following, for performance, must makes changes in many
        # other equations
        # vX = atleast_2d(X.ravel()).T

    # vectorize numbers
    elif isnumericscalar(X):
        vX = np.atleast_2d(np.array(X))

    # vectorize dictionaries
    elif isinstance(X, dict):
        for k in sorted(X.keys()):
            vX = np.concatenate((vX, spm_vec(X[k])))

    # vectorize generic objects
    # TODO: handle objects with __slots__
    elif hasattr(X, '__dict__'):
        for k in sorted(X.__dict__.keys()):
            vX = np.concatenate((vX, spm_vec(X.__dict__[k])))

    # vectorise tuples and lists into numpy arrays
    # --------------------------------------------------------------------------
    elif isinstance(X, (list, tuple)):
        for i in X:
            vX = np.concatenate((vX, spm_vec(i)))

    # vectorize object arrays
    elif isobjectarray(X):
        for item in np.nditer(X.ravel(order='F'), flags=('refs_ok',)):
            vX = np.concatenate((vX, spm_vec(item.item())))

    return vX


def spm_unvec(vX, *args):
    """
    Unvectorise a vectorised array - a compiled routine
    FORMAT [varargout] = spm_unvec(vX,varargin)
    varargin  - numeric, cell or structure array
    vX        - spm_vec(X)

    i.e. X           = spm_unvec(spm_vec(X),X)
     [X1,X2,...] = spm_unvec(spm_vec(X1,X2,...),X1,X2,...)

    See spm_vec
    _________________________________________________________________________
    Copyright (C) 2005-2014 Wellcome Trust Centre for Neuroimaging

    Karl Friston
    $Id: spm_unvec.m 6238 2014-10-13 09:38:23Z karl $


    error('spm_unvec.c not compiled - see Makefile')
    """

    # deal to multiple outputs if necessary... Not
    # --------------------------------------------------------------------------
    # python can just unpack output as needed

    if len(args) == 1:
        X = copy.copy(args[0])
    else:
        X = copy.copy(args)

    # check vX is numeric (...numpy array)
    # --------------------------------------------------------------------------
    if not isnumericarray(vX):
        vX = spm_vec(vX)

    # reshape numerical arrays
    # --------------------------------------------------------------------------
    if isnumericarray(X):
        # forcefully convert to float, to be in the safe side
        X = X.astype(float, copy=False)
        # no need to check for X dimensions
        X[:] = vX.reshape(X.shape, order='F')
        return X

    if isnumericscalar(X):
        return vX[0]

    # fill in object arrays (equivalent to matlab cells)
    if isobjectarray(X):
        for i in range(np.size(X)):
            if isinstance(X[i], np.ndarray):
                n = X[i].size
            else:
                n = spm_length(X[i])
            X[i] = spm_unvec(vX[0:n], X[i])
            vX = vX[n:]
        return X

    # fill in lists
    # --------------------------------------------------------------------------
    if isinstance(X, (list, tuple)):
        X = list(X)
        for i in range(len(X)):
            if isinstance(X[i], np.ndarray):
                n = X[i].size
            else:
                n = spm_length(X[i])
            X[i] = spm_unvec(vX[0:n], X[i])
            vX = vX[n:]
        return X

    # fill in generic objects
    # equivalent to matlab structs?
    if hasattr(X, '__dict__'):
        for k in sorted(X.__dict__.keys()):
            c = copy.copy(X.__dict__[k])
            if isinstance(c, np.ndarray):
                n = np.size(c)
            else:
                n = spm_length(c)
            c = spm_unvec(vX[0:n], c)
            # deal...?
            setattr(X, k, c)
            vX = vX[n:]
        return X

    # fill in dictionaries
    # redundant code is redundant
    if isinstance(X, dict):
        for k in sorted(X.keys()):
            c = copy.copy(X[k])
            if isinstance(c, np.ndarray):
                n = np.size(c)
            else:
                n = spm_length(c)
            c = spm_unvec(vX[0:n], c)
            # deal...?
            X[k] = c
            vX = vX[n:]
        return X

    # else
    # --------------------------------------------------------------------------
    # X         = empty(0)
    return None



def spm_dcm_fmri_priors(A, B, C, D, options):
    """
    Returns the priors for a two-state DCM for fMRI.
    FORMAT:[pE,pC,x] = spm_dcm_fmri_priors(A,B,C,D,options)

      options.two_state:  (0 or 1) one or two states per region
      options.stochastic: (0 or 1) exogenous or endogenous fluctuations
      options.precision:           log precision on connection rates

    INPUT:
       A,B,C,D - constraints on connections (1 - present, 0 - absent)

    OUTPUT:
       pE     - prior expectations (connections and hemodynamic)
       pC     - prior covariances  (connections and hemodynamic)
       x      - prior (initial) states
    _________________________________________________________________________

    References for state equations:
    1. Marreiros AC, Kiebel SJ, Friston KJ. Dynamic causal modelling for
       fMRI: a two-state model.
       Neuroimage. 2008 Jan 1;39(1):269-78.

    2. Stephan KE, Kasper L, Harrison LM, Daunizeau J, den Ouden HE,
       Breakspear M, Friston KJ. Nonlinear dynamic causal models for fMRI.
       Neuroimage 42:649-662, 2008.
    _________________________________________________________________________
    Copyright (C) 2008 Wellcome Trust Centre for Neuroimaging

    Karl Friston
    $Id: spm_dcm_fmri_priors.m 7270 2018-03-04 13:08:10Z karl $
    """

    options = copy.copy(options)

    # number of regions
    # --------------------------------------------------------------------------
    # n = A.shape[0]
    if np.ndim(A) > 0:
        n = np.shape(A)[0]
    else:
        n = 0

    # check options and D (for nonlinear coupling)
    # --------------------------------------------------------------------------
    if not 'stochastic' in options:
        options['stochastic'] = 0
    if not 'induced' in options:
        options['induced'] = 0
    if not 'two_state' in options:
        options['two_state'] = 0
    if not 'backwards' in options:
        options['backwards'] = 0
    if not np.size(D) > 0:
        D = np.zeros((n, n, 0))

    pE = {}
    pC = {}
    # connectivity priors and intitial states
    # ==========================================================================
    if options['two_state']:

        # (6) initial states
        # ----------------------------------------------------------------------
        x = np.zeros((n, 6))  # matlab: sparse(n,6)
        A = (A - np.diag(np.diag(A))).astype(bool)

        if 'precision' in options:
            pA = options['precision']
        else:
            pA = 16

        # prior expectations and variances
        # ----------------------------------------------------------------------
        pE['A'] = (A + np.eye(n)) * 32 - 32
        pE['B'] = B * 0
        pE['C'] = C * 0
        pE['D'] = D * 0

        # prior covariances
        # ----------------------------------------------------------------------
        A = np.atleast_3d(A)
        pC['A'] = np.zeros(A.shape)
        for i in range(A.shape[2]):
            pC['A'][:, :, i] = A[:, :, i] / pA + np.eye(n) / pA
        pC['B'] = B / 4
        pC['C'] = C * 4
        pC['D'] = D / 4

        # excitatory proportion
        # ----------------------------------------------------------------------
        if options['backwards']:
            pE['A'][:, :, 1] = A * 0
            pC['A'][:, :, 1] = A / pA

    else:

        # one hidden state per node
        # ======================================================================

        # (6 - 1) initial states
        # ----------------------------------------------------------------------
        x = np.zeros((n, 5))  # matlab: sparse(n,5)

        # precision of connections (one-state)
        # ---------------------------------------------------------------------
        if 'precision' in options:
            pA = options['precision']
        else:
            pA = 64

        if 'decay' in options:
            dA = options['decay']
        else:
            dA = 1

        # prior expectations
        # ----------------------------------------------------------------------
        if isvector(A):
            A = np.array(A).astype(bool)
            pE['A'] = (A.ravel() - 1) * dA
        else:
            A = (A - np.diag(np.diag(A))).astype(bool)
            pE['A'] = A / 128
        pE['B'] = B * 0
        pE['C'] = C * 0
        pE['D'] = D * 0

        # prior covariances
        # ----------------------------------------------------------------------
        if isvector(A):
            pC['A'] = A.ravel()
        else:
            A = np.atleast_3d(A)
            pC['A'] = np.zeros(A.shape)
            for i in range(A.shape[2]):
                pC['A'][:, :, i] = A[:, :, i] / pA + np.eye(n) / pA
        pC['B'] = B
        pC['C'] = C
        pC['D'] = D

    # and add hemodynamic priors
    # ==========================================================================

    # matlab: sparse(...) for all vars below
    pE['transit'] = np.zeros((n, 1))
    pC['transit'] = np.zeros((n, 1)) + 1 / 256
    pE['decay'] = np.zeros((1, 1))
    pC['decay'] = np.zeros((1, 1)) + 1 / 256
    pE['epsilon'] = np.zeros((1, 1))
    pC['epsilon'] = np.zeros((1, 1)) + 1 / 256

    # add prior on spectral density of fluctuations (amplitude and exponent)
    # --------------------------------------------------------------------------
    # matlab: sparse(...) for all vars below
    if options['induced']:
        # neuronal fluctuations
        pE['a'] = np.zeros((2, 1))
        pC['a'] = np.zeros((2, 1)) + 1 / 64
        # channel noise global
        pE['b'] = np.zeros((2, 1))
        pC['b'] = np.zeros((2, 1)) + 1 / 64
        # channel noise specific
        pE['c'] = np.zeros((1, n))
        pC['c'] = np.zeros((1, n)) + 1 / 64

    # prior covariance matrix
    # --------------------------------------------------------------------------
    pC = np.diag(spm_vec(pC).ravel())

    return pE, pC, x


def pdcm_fmri_priors(A, B, C, D, options):

    pE = {}
    pC = {}

    # number of regions
    # --------------------------------------------------------------------------
    n = A.shape[0]

    # connectivity priors and intitial states
    # ==========================================================================
    # Havlicek 2015, supplementary info 5

    # initial states (6)
    #----------------------------------------------------------------------
    x  = np.zeros((n, 6))

    # priors for A borrowed from 1S-DCM
    # precision of connections
    # ---------------------------------------------------------------------
    if 'precision' in options:
        pA = exp(options['precision'])
    else:
        pA = 64
    if 'decay' in options:
        dA = options['decay']
    else:
        dA = 1

    # prior expectations
    # ----------------------------------------------------------------------
    if isvector(A):
        A = A.astype(bool)
        pE['A']  = (A.ravel() - 1) * dA
    else:
        A = (A - np.diag(np.diag(A))).astype(bool)
        pE['A']  = A / 128
    pE['B']  = B * 0
    pE['C']  = C * 0
    pE['D']  = D * 0

    # prior covariances
    # ----------------------------------------------------------------------
    if isvector(A):
        pC['A']  = A.ravel()
    else:
        A = np.atleast_3d(A)
        pC['A'] = np.zeros(A.shape)
        for i in range(A.shape[2]):
            pC['A'][:, :, i] = A[:, :, i] / pA + np.eye(n,n) / pA
    pC['B']  = B.astype(bool) * exp(-2)  # = B
    pC['C']  = C.astype(bool) * exp(-1)  # = C
    pC['D']  = D.astype(bool) * exp(-2)  # = D

    # other neuronal priors
    # ----------------------------------------------------------------------
    pE['sigmas']   = np.zeros((n, 1))
    pC['sigmas']   = np.zeros((n, 1)) + exp(-4)
    pE['mus']      = np.zeros((n, 1))
    pC['mus']      = np.zeros((n, 1)) + exp(-4)
    pE['lambdas']  = np.zeros((n, 1))
    pC['lambdas']  = np.zeros((n, 1)) + exp(-4)

    # hemodynamic priors
    # =======================================================================
    pE['transit'] = np.zeros((n, 1))
    pC['transit'] = np.zeros((n, 1)) + exp(-4)
    pE['signaldecay'] = np.zeros((1, 1))
    pC['signaldecay'] = np.exp(-4)  # not fit?
    # pE['decay'] = zeros((1, 1))
    # pC['decay'] = exp(-4)

    pE['epsilon'] = np.zeros((1, 1))
    pC['epsilon'] = np.exp(-6)

    # p-dcm specific
    # ----------------------------------------------------------------------
    pE['gain']      = np.zeros((1, 1))
    pC['gain']      = np.exp(-4)
    pE['flowdecay'] = np.zeros((1, 1))
    pC['flowdecay'] = 1  # not fit
    pE['visco']     = np.zeros((1, 1))
    pC['visco']     = np.exp(-2)

    # prior covariance matrix
    # --------------------------------------------------------------------------
    pC = np.diag(spm_vec(pC).ravel())

    return pE, pC, x




def spm_svd(X, U=1e-6, *args, **kwargs):
    """
    Computationally efficient SVD (that can handle sparse arguments)
    FORMAT [U,S,V] = spm_svd(X,u)
    X    - (m x n) matrix
    u    - threshold (1 > u > 0) for normalized eigenvalues (default = 1e-6)
         - a value of zero induces u = 64*eps

    U    - {m x p} singular vectors
    V    - {m x p} singular variates
    S    - {p x p} singular values
    _________________________________________________________________________
    Copyright (C) 1994-2011 Wellcome Trust Centre for Neuroimaging

    Karl Friston
    $Id: spm_svd.m 6110 2014-07-21 09:36:13Z karl $
    """

    # default thresholds - preclude singular vectors with small singular values
    # --------------------------------------------------------------------------
    if U >= 1:
        U = U - 1e-6
    if U <= 0:
        U = 64 * np.spacing(1)

    # deal with sparse matrices
    # --------------------------------------------------------------------------
    # TODO: sparse, someday
    M, N = X.shape
    p = np.nonzero(np.any(X, axis=1))[0]
    q = np.nonzero(np.any(X, axis=0))[0]
    X = X[np.ix_(p, q)]

    # SVD
    # --------------------------------------------------------------------------
    i, j = np.nonzero(X)
    s = X[i, j]
    m, n = X.shape
    # TODO: check for bugs with potential 0 indices
    if np.any(i - j):  # matlab: any(i - j)

        # off-leading diagonal elements - full SVD
        # ----------------------------------------------------------------------
        # matlab: X = full(X) ... remove sparseness
        # TODO!!
        # raise Exception('spm_svd: off-leading diagonal elements not implemented')
        # return LA.svd(X, *args, **kwargs)

        U,S,V = scipy.linalg.svd(X)
        return U, S, V

    else:
        S = np.zeros((m, n))  # matlab: sparse(1:n, 1:n, s, m, n)
        S[(np.arange(n), np.arange(n))] = s  # why ix_ is not needed here?
        u = np.eye(m, n)  # matlab: speye
        v = np.eye(m, n)  # matlab: speye
        j = np.argsort(-s)  # matlab: sort(-s)
        i = -s[j]
        S = S[np.ix_(j, j)]  # but ix_ is needed here?
        v = v[:, j]
        u = u[:, j]
        s = S.diagonal()**2
        j = np.nonzero((s * max(np.shape(s) / np.sum(s))).ravel() > U)[0]
        v = v[:, j]
        u = u[:, j]
        S = S[np.ix_(j, j)]

    # replace in full matrices
    # --------------------------------------------------------------------------
    j = max(j.shape)
    U = np.zeros((M, j))  # matlab: sparse(...)
    V = np.zeros((N, j))  # matlab: sparse(...)
    if j:
        U[p, :] = u
        V[q, :] = v

    return U, S, V



def fx_fmri_pdcm(x, u, P, M=None):
    """
    P-DCM State equation for a dynamic [bilinear/nonlinear/Balloon] model of fMRI
    responses
    FORMAT [f,dfdx,D,dfdu] = spm_fx_fmri(x,u,P,M)
    x      - state vector
    x(:,1) - excitatory neuronal activity            ue
    x(:,2) - vascular signal                          s
    x(:,3) - rCBF                                  ln(f)
    x(:,4) - venous volume                         ln(v)
    x(:,5) - deoyxHb                               ln(q)
    [x(:,6) - inhibitory neuronal activity             ui
    """

    # neuronal parameters
    #--------------------------------------------------------------------------
    MU = 0.4      # , excitatory self connection (Hz)
    SIGMA = 0.5   # , inhibitory-excitatory connection (Hz)
    LAMBDA = 0.2  # , inhibitory gain factor (Hz)

    # neurovascular coupling parameters
    #--------------------------------------------------------------------------
    PHId  = 0.6   # , decay of vasoactive signal(Hz), maybe fixed?
    PHIg  = 1.5   # , gain of vasoactive signal (Hz), maybe fixed?
    CHI   = 0.6   # , decay of blood inflow signal (Hz), fixed

    # hemodynamic model parameters
    #--------------------------------------------------------------------------
    MTT   = 2.00  # mean transit time (sec)
    TAU   = 4     # , viscoelastic time (sec)
    ALPHA = 0.32  # , aka Grubb's exp
    E0    = 0.4   # oxygen extraction fraction at rest

    P = copy.deepcopy(P)
    # Neuronal motion
    #==========================================================================
    # matlab: takes full() of A, B and D
    P['A'] = np.atleast_1d(dense(P['A']))                       # linear parameters
    P['B'] = np.atleast_1d(dense(P['B']))                       # bi-linear parameters
    P['C'] = np.atleast_1d(P['C']) / 16                    # exogenous parameters

    n  = P['A'].shape[0]            # number of regions
    uB = np.zeros((n, n))

    # implement differential state equation y = dx/dt (neuronal)
    #--------------------------------------------------------------------------
    f = copy.copy(x)
    x = copy.copy(x)

    # two neuronal states per region
    #======================================================================

    # input dependent modulation
    #----------------------------------------------------------------------
    for i in range(P['B'].shape[2]):
        uB = uB + u[i] * P['B'][:,:,i]

    # extrinsic (two neuronal states)
    #----------------------------------------------------------------------

    # P-DCM equations:
    #  d/dt Xe[t] = J[+] * Xe[t] + J[-] * Xi[t] +  C * U[t]
    #  d/dt Xi[t] = [Xe[t] - Xi[t]]
    #
    #  J[+]_ij = A + uB
    #  J[-]_ij = 0
    #  G_ij    = 0
    #
    #  J[+]_ii = - * exp(~ + uB)
    #  J[-]_ii = - * exp(~_i + b_i * u_k)
    #  G_ii    =   * exp(~_i + b_i * u_l )

    I = np.eye(n).astype(bool)
    JP = P['A'] + uB
    JN = np.zeros((n, n))
    G  = np.zeros((n, n))


    JP[I] = - SIGMA * exp(P['sigmas'].ravel() + np.diag(uB))
    JN[I] = - MU * exp(P['mus'].ravel() + np.diag(uB))
    G[I]  = LAMBDA * exp(P['lambdas'].ravel() + np.diag(uB))

    # motion - excitatory and inhibitory: f = dx/dt
    #----------------------------------------------------------------------
    # d/dt Xe[t] = J[+] *  Xe[t] + J[-] *  Xi[t] +   C * U[t]
    f[:, 0] =  JP  @ x[:, 0] + JN   @ x[:, 5] + P['C'] @ u.ravel()
    # d/dt Xi[t] = G * ( Xe[t] - Xi[t] )
    f[:, 5] =  G @ (x[:,0] - x[:,5])

    # Hemodynamic motion
    #==========================================================================

    # neurovascular coupling and hemodynamic variables
    #--------------------------------------------------------------------------
    #  a[t]: vasoactive signal
    #  f[t]: blood flow
    #  v[t]: blood volume
    #  q[t]: dHb content
    #
    # neurovascular equations
    #--------------------------------------------------------------------------
    #  d/dt a[t] = - * a[t] + x[t]
    #  d/dt f[t] =   * a[t] -  * [f[t] - 1]
    #
    # hemodynamic equations (same as 1s and 2d dcm)
    #--------------------------------------------------------------------------
    #  d/dt v[t] = 1/MTT * [f[t] - fout(v,t)]
    #  d/dt q[t] = 1/MTT * [f[t] * E[f] / E0 - fout(v,t) * q[t]/v[t]]

    # exponentiation of hemodynamic state variables
    #--------------------------------------------------------------------------
    x[:, 2:5] = np.exp(x[:, 2:5])  # f, v, q

    # scale variables
    #--------------------------------------------------------------------------
    sd  = PHId * np.exp(P['signaldecay']).ravel()  #  signal decay
    sg  = PHIg * np.exp(P['gain']).ravel()         #  signal gain
    #fd  = CHI * exp(P['flowdecay']).ravel()    #  flow decay
    fd  = CHI                        # not fit (suppl. info 5)
    tt  = MTT * np.exp(P['transit']).ravel()       # transit time, fit (suppl. info 5)
    vt  = TAU * np.exp(P['visco']).ravel()         #  viscoelastic time, fit

    # Fout = f[v] - outflow             fout(v,t)
    #--------------------------------------------------------------------------
    # P-DCM includes a viscoelastic effect
    fv = (tt *  x[:, 3] ** (1 / ALPHA) + vt * x[:, 2]) / (vt + tt)

    # e = f[f] - oxygen extraction      E[f]/E0
    #--------------------------------------------------------------------------
    ff = (1 - (1 - E0) ** (1 / x[:, 2])) / E0

    # a[t]: vasoactive signal
    #--------------------------------------------------------------------------
    f[:, 1] = - sd * x[:, 1] + x[:, 0]

    # f[t]: flow  (log units)
    #--------------------------------------------------------------------------
    f[:, 2] = (sg * x[:, 1] - fd * (x[:, 2] - 1)) / x[:, 2]

    # v[t]: blood volume  (log units)
    #--------------------------------------------------------------------------
    f[:, 3] =  (x[:, 2] - fv) / (tt * x[:, 3])

    # q[t]: dHB content  (log units)
    #--------------------------------------------------------------------------
    f[:, 4] = (ff  * x[:, 2] - fv  * x[:, 4] / x[:, 3]) / (tt * x[:, 4])

    #import pdb; pdb.set_trace()

    f = f.ravel(order='F')

    # if nargout < 2, return, end

    # TODO: Jacobians

    return f


def spm_fx_fmri(x, u, P, M=None):
    """
    State equation for a dynamic [bilinear/nonlinear/Balloon] model of fMRI
    responses
    FORMAT [f,dfdx,D,dfdu] = spm_fx_fmri(x,u,P,M)
    x      - state vector
      x(:,1) - excitatory neuronal activity            ue
      x(:,2) - vascular signal                          s
      x(:,3) - rCBF                                  ln(f)
      x(:,4) - venous volume                         ln(v)
      x(:,5) - deoyxHb                               ln(q)
     [x(:,6) - inhibitory neuronal activity             ui

    f      - dx/dt
    dfdx   - df/dx
    dfdu   - df/du
    D      - delays

    _________________________________________________________________________

    References for hemodynamic & neuronal state equations:
    1. Buxton RB, Wong EC & Frank LR. Dynamics of blood flow and oxygenation
       changes during brain activation: The Balloon model. MRM 39:855-864,
       1998.
    2. Friston KJ, Mechelli A, Turner R, Price CJ. Nonlinear responses in
       fMRI: the Balloon model, Volterra kernels, and other hemodynamics.
       Neuroimage 12:466-477, 2000.
    3. Stephan KE, Kasper L, Harrison LM, Daunizeau J, den Ouden HE,
       Breakspear M, Friston KJ. Nonlinear dynamic causal models for fMRI.
       Neuroimage 42:649-662, 2008.
    4. Marreiros AC, Kiebel SJ, Friston KJ. Dynamic causal modelling for
       fMRI: a two-state model.
       Neuroimage. 2008 Jan 1;39(1):269-78.
    _________________________________________________________________________
    Copyright (C) 2002-2014 Wellcome Trust Centre for Neuroimaging

    Karl Friston & Klaas Enno Stephan
    $Id: spm_fx_fmri.m 7270 2018-03-04 13:08:10Z karl $

    """

    # options
    # --------------------------------------------------------------------------
    if M is None:
        M = {}

    if 'symmetry' in M:
        symmetry = M['symmetry']
    else:
        symmetry = 0

    # needed to avoid overwriting original object members
    P = copy.deepcopy(P)

    # Neuronal motion
    # ==========================================================================
    # matlab: takes full() of A, B and D
    P['A'] = np.atleast_1d(dense(P['A']))                       # linear parameters
    P['B'] = np.atleast_1d(dense(P['B']))                       # bi-linear parameters
    P['C'] = np.atleast_1d(P['C']) / 16                    # exogenous parameters
    P['D'] = np.atleast_1d(dense(P['D']))                       # nonlinear parameters

    u = np.atleast_1d(u)
    x = np.atleast_2d(x).astype(float)  # astype() copies the data

    # implement differential state equation y = dx/dt (neuronal)
    # --------------------------------------------------------------------------
    f = copy.copy(x)

    # if there are five hidden states per region, only one is neuronal
    # ==========================================================================
    if x.shape[1] == 5:
        # if P['A'] encodes the eigenvalues of the (average) connectivity matrix
        # ======================================================================
        if np.size(P['A']) > 1 and isvector(P['A']):
            # TODO
            # print('P[A] = {}'.format(P['A']))
            raise Exception('Not implemented for P["A"] as vector')

        else:
            # otherwise average connections are encoded explicitly
            # ==================================================================

            # input dependent modulation
            # ------------------------------------------------------------------
            # TODO: streamline this
            if np.ndim(P['B']) > 2:
                if np.ndim(P['A']) > 2:
                    for i in range(P['B'].shape[2]):
                        P['A'][:, :, 0] = P['A'][:, :, 0] + u[i] * P['B'][:, :, i]
                else:
                    for i in range(P['B'].shape[2]):
                        # print('shape of P[A] = {}'.format(np.shape(P['A'])))
                        # print('shape of P[B] = {}'.format(np.shape(P['B'])))
                        # print('shape of u = {}'.format(np.shape(u)))
                        P['A'][:, :] = P['A'][:, :] + u[i] * P['B'][:, :, i]
            else:
                P['A'] = P['A'] + u[0] * P['B']

            # and nonlinear (state) terms
            # ------------------------------------------------------------------
            if np.ndim(P['D']) > 2:
                for i in range(P['D'].shape[2]):
                    P['A'][:, :, 0] = P['A'][:, :, 0] + x[i, 0] * P['D'][:, :, i]

            # combine forward and backward connections if necessary
            if np.ndim(P['A']) > 2 and P['A'].shape[2] > 1:
                P['A'] = exp(P['A'][:, :, 0]) - exp(P['A'][:, :, 1])

            # one neuronal state per region: diag(A) is a log self-inhibition
            # ------------------------------------------------------------------
            SE = np.diag(P['A'])
            EE = P['A'] - np.diag(np.exp(SE) / 2 + SE)

            # symmetry constraints for demonstration purposes
            # ------------------------------------------------------------------
            if symmetry:
                EE = (EE + EE.T) / 2

        # flow
        # ----------------------------------------------------------------------
        # print('line 1793: size of EE = {}'.format(np.shape(EE)))
        # print('           size of x = {}'.format(np.shape(x)))
        # print('           size of P[C] = {}'.format(np.shape(P['C'])))
        # print('           size of u.ravel() = {}'.format(np.shape(u.ravel())))
        # print('           size of u = {}'.format(np.shape(u)))

        f[:, 0] = EE @ x[:, 0] + P['C'] @ u.ravel()

    else:

        # otherwise two neuronal states per region
        # ======================================================================

        # input dependent modulation
        # ----------------------------------------------------------------------
        # TODO: streamline this
        if np.ndim(P['B']) > 2:
            if np.ndim(P['A']) > 2:
                for i in range(P['B'].shape[2]):
                    P['A'][:, :, 0] = P['A'][:, :, 0] + u[i] * P['B'][:, :, i]
            else:
                for i in range(P['B'].shape[2]):
                    P['A'][:, :] = P['A'][:, :] + u[i] * P['B'][:, :, i]
        else:
            P['A'] = P['A'] + u[0] * P['B']

        # and nonlinear (state) terms
        # ----------------------------------------------------------------------
        if np.ndim(P['D']) > 2:
            for i in range(P['D'].shape[2]):
                P['A'][:, :, 0] = P['A'][:, :, 0] + x[i, 0] @ P['D'][:, :, i]

        # extrinsic (two neuronal states): enforce positivity
        # ----------------------------------------------------------------------
        n = P['A'].shape[0]          # number of regions
        # TODO: streamline this
        if np.ndim(P['A']) > 2:
            EE = np.exp(P['A'][:, :, 0]) / 8
        else:
            EE = np.exp(P['A'][:, :]) / 8
        IE = diag(np.diag(EE))         # intrinsic inhibitory to excitatory
        EE = EE - IE                # extrinsic excitatory to excitatory
        EI = np.eye(n)                 # intrinsic excitatory to inhibitory
        SE = np.eye(n) / 2             # intrinsic self-inhibition (excitatory)
        SI = np.eye(n)                 # intrinsic self-inhibition (inhibitory)

        # excitatory proportion
        # ----------------------------------------------------------------------
        if P['A'].ndim > 2 and P['A'].shape[2] > 1:
            phi = spm_phi(P['A'][:, :, 1] * 2)
            EI = EI + EE * (1 - phi)
            EE = EE * phi - SE
        else:
            EE = EE - SE

        # motion - excitatory and inhibitory: f = dx/dt
        # ----------------------------------------------------------------------
        f[:, 0] = EE @ x[:, 0] - IE @ x[:, 5] + P['C'] @ u.ravel()
        f[:, 5] = EI @ x[:, 0] - SI @ x[:, 5]

    # Hemodynamic motion
    # ==========================================================================

    # hemodynamic parameters
    # --------------------------------------------------------------------------
    #   H(0) - signal decay                                   d(ds/dt)/ds)
    #   H(1) - autoregulation                                 d(ds/dt)/df)
    #   H(2) - transit time                                   (t0)
    #   H(3) - exponent for Fout(v)                           (alpha)
    #   H(4) - resting oxygen extraction                      (E0)
    #   H(5) - ratio of intra- to extra-vascular components   (epsilon)
    #          of the gradient echo signal
    # --------------------------------------------------------------------------
    if 'H' in P:
        H = P['H']
    else:
        H = np.array([0.64, 0.32, 2.00, 0.32, 0.4])

    # exponentiation of hemodynamic state variables
    # --------------------------------------------------------------------------
    x[:, 2:5] = np.exp(x[:, 2:5])

    # signal decay
    # --------------------------------------------------------------------------
    sd = H[0] * np.exp(P['decay'].ravel())

    # transit time
    # --------------------------------------------------------------------------
    tt = H[2] * np.exp(P['transit'].ravel())

    # Fout = f(v) - outflow
    # --------------------------------------------------------------------------
    fv = x[:, 3]**(1 / H[3])

    # e = f(f) - oxygen extraction
    # --------------------------------------------------------------------------
    ff = (1 - (1 - H[4])**(1 / x[:, 2])) / H[4]

    # implement differential state equation f = dx/dt (hemodynamic)
    # --------------------------------------------------------------------------
    f[:, 1] = x[:, 0] - sd * x[:, 1] - H[1] * (x[:, 2] - 1)
    f[:, 2] = x[:, 1] / x[:, 2]
    f[:, 3] = (x[:, 2] - fv) / (tt * x[:, 3])
    f[:, 4] = (ff * x[:, 2] - fv * x[:, 4] / x[:, 3]) / (tt * x[:, 4])
    f = f.ravel(order='F')

    return f


# notice that arg M is not used
# not setting its default arg might give issues with 3 arg lambdas at spm_DEM_* functions
def spm_gx_fmri(x, u, P, M=None):
    """
    Simulated BOLD response to input
    FORMAT [g,dgdx] = spm_gx_fmri(x,u,P,M)
    g          - BOLD response (%)
    x          - state vector     (see spm_fx_fmri)
    P          - Parameter vector (see spm_fx_fmri)
    M          - model specification structure (see spm_nlsi)
    _________________________________________________________________________

    This function implements the BOLD signal model described in:

    Stephan KE, Weiskopf N, Drysdale PM, Robinson PA, Friston KJ (2007)
    Comparing hemodynamic models with DCM. NeuroImage 38: 387-401.
    _________________________________________________________________________
    Copyright (C) 2008 Wellcome Trust Centre for Neuroimaging

    Karl Friston & Klaas Enno Stephan
    $Id: spm_gx_fmri.m 6262 2014-11-17 13:47:56Z karl $
    """

    x = np.atleast_2d(x)

    # Biophysical constants for 1.5T
    # ==========================================================================

    # time to echo (TE) (default 0.04 sec)
    # --------------------------------------------------------------------------
    TE = 0.04

    # resting venous volume (%)
    # --------------------------------------------------------------------------
    V0 = 4

    # estimated region-specific ratios of intra- to extra-vascular signal
    # --------------------------------------------------------------------------
    ep = np.exp(P['epsilon'])

    # slope r0 of intravascular relaxation rate R_iv as a function of oxygen
    # saturation S:  R_iv = r0*[(1 - S)-(1 - S0)] (Hz)
    # --------------------------------------------------------------------------
    r0 = 25

    # frequency offset at the outer surface of magnetized vessels (Hz)
    # --------------------------------------------------------------------------
    nu0 = 40.3

    # resting oxygen extraction fraction
    # --------------------------------------------------------------------------
    E0 = 0.4

    # Coefficients in BOLD signal model
    # ==========================================================================
    k1 = 4.3 * nu0 * E0 * TE
    k2 = ep * r0 * E0 * TE
    k3 = 1 - ep

    # Output equation of BOLD signal model
    # ==========================================================================
    v = np.exp(x[:, 3])
    q = np.exp(x[:, 4])
    # g = V0 @ ...
    g = V0 * (k1 - k1 * q + k2 - k2 * q / v + k3 - k3 * v)

    # matlab: if nargout == 1, return, end

    # TODO: # derivative dgdx
    # ==========================================================================

    return g


def spm_gx_state_fmri(x, u, P, M=None):
    """
    Simulated BOLD response and copied state vector
    FORMAT [y] = spm_gx_state_fmri(x,u,P,M)
    y          - BOLD response and copied state vector

    x          - state vector     (see spm_fx_fmri)
    P          - Parameter vector (see spm_fx_fmri)
    M          - model specification structure (see spm_nlsi)

    The `copied state vector' passes the first hidden variable in each region
    to the output variable y, so that 'neural activities' can be plotted
    by spm_dcm_generate.m

    See spm_fx_fmri.m and spm_dcm_generate.m
    _________________________________________________________________________
    Copyright (C) 2011 Wellcome Trust Centre for Neuroimaging

    Will Penny
    $Id: spm_gx_state_fmri.m 6262 2014-11-17 13:47:56Z karl $
    """
    y = np.atleast_2d(spm_gx_fmri(x, u, P, M)).T
    x = np.atleast_2d(x)

    # Copy first hidden state (neural activity) from each region
    # matlab: y=[y;x(i,1)] in a loop
    y = np.vstack((y, x[:, [0]]))

    y = dense(y)  # matlab: y = full(y)
    return y.T



# [Ep,Cp,Eh,F,L,dFdp,dFdpp] = spm_nlsi_GN(M,U,Y)
def spm_nlsi_GN(M, U=[], Y={}):
    """
    Bayesian inversion of nonlinear models - Gauss-Newton/Variational Laplace
    FORMAT [Ep,Cp,Eh,F] = spm_nlsi_GN(M,U,Y)

    [Dynamic] MIMO models
    _________________________________________________________________________

    M.IS - function name f(P,M,U) - generative model
           This function specifies the nonlinear model:
             y = Y.y = IS(P,M,U) + X0*P0 + e
           where e ~ N(0,C). For dynamic systems this would be an integration
           scheme (e.g. spm_integ). spm_integ expects the following:

        M.f  - f(x,u,P,M)
        M.g  - g(x,u,P,M)
        M.h  - h(x,u,P,M)
          x  - state variables
          u  - inputs or causes
          P  - free parameters
          M  - fixed functional forms and parameters in M

    M.FS - function name f(y,M)   - feature selection
           This [optional] function performs feature selection assuming the
           generalized model y = FS(y,M) = FS(IS(P,M,U),M) + X0*P0 + e

    M.P  - starting estimates for model parameters [optional]

    M.pE - prior expectation      - E{P}   of model parameters
    M.pC - prior covariance       - Cov{P} of model parameters

    M.hE - prior expectation      - E{h}   of log-precision parameters
    M.hC - prior covariance       - Cov{h} of log-precision parameters

    U.u  - inputs (or just U)
    U.dt - sampling interval

    Y.y  - outputs (samples x observations x ...)
    Y.dt - sampling interval for outputs
    Y.X0 - confounds or null space      (over size(y,1) samples or all vec(y))
    Y.Q  - q error precision components (over size(y,1) samples or all vec(y))


    Parameter estimates
    -------------------------------------------------------------------------
    Ep  - (p x 1)         conditional expectation    E{P|y}
    Cp  - (p x p)         conditional covariance     Cov{P|y}
    Eh  - (q x 1)         conditional log-precisions E{h|y}

    log evidence
    -------------------------------------------------------------------------
    F   - [-ve] free energy F = log evidence = p(y|f,g,pE,pC) = p(y|m)

    _________________________________________________________________________
    Returns the moments of the posterior p.d.f. of the parameters of a
    nonlinear model specified by IS(P,M,U) under Gaussian assumptions.
    Usually, IS is an integrator of a dynamic MIMO input-state-output model

                 dx/dt = f(x,u,P)
                 y     = g(x,u,P)  + X0*P0 + e

    A static nonlinear observation model with fixed input or causes u
    obtains when x = []. i.e.

                 y     = g([],u,P) + X0*P0e + e

    but static nonlinear models are specified more simply using

                 y     = IS(P,M,U) + X0*P0 + e

    Priors on the free parameters P are specified in terms of expectation pE
    and covariance pC. The E-Step uses a Fisher-Scoring scheme and a Laplace
    approximation to estimate the conditional expectation and covariance of P
    If the free-energy starts to increase,  an abbreviated descent is
    invoked.  The M-Step estimates the precision components of e, in terms
    of log-precisions.  Although these two steps can be thought of in
    terms of E and N steps they are in fact variational steps of a full
    variational Laplace scheme that accommodates conditional uncertainty
    over both parameters and log precisions (c.f. hyperparameters with hyper
    priors)

    An optional feature selection can be specified with parameters M.FS.

    For generic aspects of the scheme see:

    Friston K, Mattout J, Trujillo-Barreto N, Ashburner J, Penny W.
    Variational free energy and the Laplace approximation.
    NeuroImage. 2007 Jan 1;34(1):220-34.

    This scheme handels complex data along the lines originally described in:

    Sehpard RJ, Lordan BP, and Grant EH.
    Least squares analysis of complex data with applications to permittivity
    measurements.
    J. Phys. D. Appl. Phys 1970 3:1759-1764.

    _________________________________________________________________________
    Copyright (C) 2001-2015 Wellcome Trust Centre for Neuroimaging

    Karl Friston
    $Id: spm_nlsi_GN.m 7279 2018-03-10 21:22:44Z karl $
    """
    # options
    # --------------------------------------------------------------------------
    if not 'nograph' in M:
        M['nograph'] = True  # matlab: = 0, let's not use guis for now
    if not 'noprint' in M:
        M['noprint'] = False
    if not 'Nmax' in M:
        M['Nmax'] = 128

    # figure (unless disabled)
    # --------------------------------------------------------------------------
    # TODO?

    # check integrator
    # --------------------------------------------------------------------------
    if not 'IS' in M:
        M['IS'] = 'spm_int'

    # composition of feature selection and prediction (usually an integrator)
    # --------------------------------------------------------------------------
    if 'y' in Y:
        y = Y['y']
    else:
        y = Y

    # TODO: make this section safer, without eval?
    try:

        # try FS(y,M)
        # ----------------------------------------------------------------------
        try:
            # obs: M['FS'] might not exist
            y = eval(M['FS'])(y, M)
            # TODO: make this more clear, change formatting?
            IS_code = 'lambda P, M, U:' + M['FS'] + '(' + M['IS'] + '(P, M, U), M)'
            IS = eval(IS_code)

            # try FS(y)
            # ------------------------------------------------------------------
        except:
            y = eval(M['FS'])(y)
            IS_code = 'lambda P, M, U:' + M['FS'] + '(' + M['IS'] + '(P, M, U))'
            IS = eval(IS_code)
    except:
        # otherwise FS(y) = y
        # ----------------------------------------------------------------------
        try:
            IS_code = 'lambda P, M, U:' + M['IS'] + '(P, M, U)'
            IS = eval(IS_code)
        except:
            IS = M['IS']

    # converted to function handle
    # --------------------------------------------------------------------------
    # TODO: check if really needed
    IS = spm_funcheck(IS)

    # TODO: report typo below
    # parameter update equation
    # --------------------------------------------------------------------------
    if 'f' in M:
        M['f'] = spm_funcheck(M['f'])
    if 'g' in M:
        M['g'] = spm_funcheck(M['g'])
    if 'h' in M:
        M['h'] = spm_funcheck(M['h'])

    # size of data (samples x response component x response component ...)
    # --------------------------------------------------------------------------
    if isinstance(y, (list, tuple)):
        ns = max(y[0].shape)
    else:
        ns = y.shape[0]
    ny = spm_vec(y).shape[0]  # total number of response variables
    nr = np.floor(ny / ns).astype(int)  # number response components
    M['ns'] = ns  # number of samples M['ns']

    # initial states
    # --------------------------------------------------------------------------
    if not 'x' in M:
        if not 'n' in M:
            M['n'] = 0
        M['x'] = np.zeros(M['n'], 1)  # matlab: sparse(...)

    # input
    # --------------------------------------------------------------------------
    # unlike matlab, we can set default U = [] at function declaration

    # initial parameters
    # --------------------------------------------------------------------------
    try:
        # TODO: test/guess what could go wrong here (M['P'] might not exist. sizes could be different)
        spm_vec(M['P']) - spm_vec(M['pE'])
        print('\nParameter initialisation successful\n')
    except:
        M['P'] = copy.deepcopy(M['pE'])

    # time-step
    # --------------------------------------------------------------------------
    if 'dt' in Y:
        dt = Y['dt']
    else:
        dt = 1

    # precision components Q
    # --------------------------------------------------------------------------
    try:
        # TODO: check/guess what could go wrong here
        Q = Y['Q']
        # if not isnumericarray(Q):
        #     Q = [Q]  # matlab: Q = {Q}
    except:
        t = (ns * np.ones(nr)).astype(int)
        Q = spm_Ce(t)  # TODO: test this
    Q = np.atleast_1d(Q)
    nh = len(Q) # number of precision components
    try:
        nq = int(ny / max(np.shape(Q[0])))  # for compact Kronecker form of M-step
    except:
        nq = int(ny)

    # prior moments (assume uninformative priors if not specifed)
    # --------------------------------------------------------------------------
    # Note: very important to copy any data that will be unvec'ed
    # otherwise, it might mess up with the serialization process
    pE = copy.deepcopy(M['pE'])

    if 'pC' in M:
        pC = M['pC']
    else:
        nP = spm_length(M['pE'])
        pC = np.eye(nP) * np.exp(16)  # matlab: speye(...)

    # confounds (if specified)
    # --------------------------------------------------------------------------
    try:
        # TODO: test/guess what could go wrong here
        nb = Y['X0'].shape[0]  # number of bins
        nx = int(ny / nb)  # number of blocks
        dfdu = np.kron(np.eye(nx), Y['X0'])  # matlab: speye(...)
    except:
        dfdu = np.zeros((ny, 0))  # matlab: sparse(...)
    if dfdu.size == 0:
        dfdu = np.zeros((ny, 0))  # matlab: sparse(...)

    # hyperpriors - expectation (and initialize hyperparameters)
    # --------------------------------------------------------------------------
    try:
        # TODO: test/guess what could go wrong here
        # likely a missing hE attribute
        hE = M['hE']
        if max(hE.shape) != nh:
            hE = hE + np.zeros((nh, 1))  # matlab: sparse(...)
    except:
        hE = np.zeros((nh, 1)) - np.log(np.var(spm_vec(y), ddof=1)) + 4
    h = hE

    # hyperpriors - covariance
    # --------------------------------------------------------------------------
    try:
        # TODO: test/guess what could go wrong here
        #       likely a missing M.hC attribute
        ihC = spm_inv(M['hC'])
        if max(ihC.shape) != nh:
            ihC = ihC @ np.eye(nh)  # matlab: speye
    except:
        # TODO: find out what is this magic number 4
        ihC = np.eye(nh) * np.exp(4)

    # unpack covariance
    # --------------------------------------------------------------------------
    if isinstance(pC, dict):  # matlab: isstruct(pC)
        pC = spm_diag(spm_vec(pC))

    # dimension reduction of parameter space
    # --------------------------------------------------------------------------

    V, *_ = spm_svd(pC, 0)  # matlab: spm_svd(pC, 0)
    nu = dfdu.shape[1]  # number of parameters (confounds)
    nP = V.shape[1]  # number of parameters (effective)
    ip = np.arange(0, nP).T
    iu = np.arange(0, nu).T + nP  # matlab: (1:nu) ...

    # second-order moments (in reduced space)
    # --------------------------------------------------------------------------
    pC = V.T @ pC @ V
    uC = np.eye(nu) / 1e-8  # matlab: speye
    ipC = np.linalg.inv(spm_cat(spm_diag([pC, uC])))  # TODO: test this

    # initialize conditional density
    # --------------------------------------------------------------------------
    # TODO: be mindful that variable y requires transposition here
    # unless spm_vec returns output.ravel(order='F')
    # otherwise, wrong result
    Eu = np.linalg.pinv(dfdu) @ spm_vec(y)
    p = np.vstack((V.T @ (spm_vec(M['P']) - spm_vec(M['pE'])), Eu))
    Ep = spm_unvec(spm_vec(pE) + V @ p[ip], pE)

    # print('line 2264  M[pE] = {}'.format(M['pE']))
    # print('line 2265  Ep = {}'.format(Ep))

    # EM
    # ==========================================================================
    criterion = np.zeros(4)

    C = {}
    C['F'] = -np.inf  # free energy
    v = -4  # log ascent rate
    dFdh = np.zeros((nh, 1))
    dFdhh = np.zeros((nh, nh))
    F0 = None  # for printing F

    e_step_iters = 4
    m_step_iters = 8

    for k in range(M['Nmax']):

        # time
        # ----------------------------------------------------------------------
        tStart = time.time()  # matlab: tStart = tic

        # E-Step: prediction f, and gradients; dfdp
        # ======================================================================
        try:
            # gradients
            # ------------------------------------------------------------------
            # print('line 2289 spm_diff inputs:  IS = {}'.format(IS))
            # print('line 2289 spm_diff inputs:  IS, Ep, M, U, 0 and V = {}'.format(np.shape([V])))
            # print('                                    M = {}'.format(M))
            dfdp, f = spm_diff(IS, Ep, M, U, 0, [V])
            dfdp = spm_vec(dfdp).reshape((ny, nP), order='F')

            # check for stability
            # ------------------------------------------------------------------
            normdfdp = maxnorm(dfdp)
            revert = np.isnan(normdfdp) or normdfdp > np.exp(32)
        except ArithmeticError:
            # TODO: check for other kinds of exceptions when it doesnt converge
            logging.warning(traceback.format_exc())
            revert = True

        if revert and k > 0:
            # TODO: tests for this block
            for i in range(e_step_iters):

                # reset expansion point and increase regularization
                # --------------------------------------------------------------
                v = np.minimum(v - 2, -4)

                # E-Step: update
                # --------------------------------------------------------------
                # print('C[p] = {}'.format(C['p']))
                # print('spm_dx(dFdpp, dFdp, [v]) = {}'.format(spm_dx(dFdpp, dFdp, [v])))

                p = C['p'] + spm_dx(dFdpp, dFdp, [v])

                Ep = spm_unvec(spm_vec(pE) + V @ p[ip], pE)

                # try again
                # --------------------------------------------------------------
                try:

                    # print('line 2320 spm_diff inputs:  IS = {}'.format(IS))
                    # print('line 2320 spm_diff inputs:  IS, Ep, M, U, 0 and V = {}'.format(np.shape([V])))
                    dfdp, f, *_ = spm_diff(IS, Ep, M, U, 0, [V])
                    dfdp = spm_vec(dfdp).reshape((ny, nP), order='F')

                    # check for stability
                    # ----------------------------------------------------------
                    normdfdp = maxnorm(dfdp)
                    revert = np.isnan(normdfdp) or normdfdp > np.exp(32)
                except ArithmeticError:
                    # TODO: check for other for other kinds of exceptions when it doesnt converge
                    logging.warning(traceback.format_exc())
                    revert = True

                # break
                # --------------------------------------------------------------
                if not revert:
                    break

        # convergence failure
        # ----------------------------------------------------------------------
        if revert:
            # matlab: 'SPM:spm_nlsi_GN' is actually an error identifier
            # TODO: define custom Exception?
            raise Exception('SPM:spm_nlsi_GN: Convergence failure.')

        # prediction error and full gradients
        # ----------------------------------------------------------------------
        e = spm_vec(y) - spm_vec(f) - dfdu @ p[iu]
        J = -np.hstack((dfdp, dfdu))

        # M-step: Fisher scoring scheme to find h = max{F(p,h)}
        # ======================================================================
        for m in range(m_step_iters):

            # precision and conditional covariance
            # ------------------------------------------------------------------
            iS = 0  # matlab: sparse(0)
            for i in range(nh):
                iS = iS + Q[i] * (np.exp(-32) + np.exp(h.ravel()[i]))
            S = spm_inv(iS)
            iS = np.kron(np.eye(nq), iS)  # matlab: speye
            Pp = (J.T @ iS @ J).real
            Cp = spm_inv(Pp + ipC)

            # precision operators for M-Step
            # ------------------------------------------------------------------
            P = [None] * nh
            PS = [None] * nh
            JPJ = [None] * nh
            for i in range(nh):
                P[i] = Q[i] * np.exp(h.ravel()[i])
                PS[i] = P[i] @ S
                P[i] = np.kron(np.eye(nq), P[i])
                JPJ[i] = J.T @ P[i] @ J

            # derivatives: dLdh = dL/dh,...
            # ------------------------------------------------------------------
            for i in range(nh):
                dFdh[i, 0] = sptrace(PS[i]) * nq / 2        \
                             - (e.T @ P[i] @ e).real / 2  \
                             - spm_trace(Cp, JPJ[i]) / 2
                for j in range(i, nh):
                    dFdhh[i, j] = - spm_trace(PS[i], PS[j]) * nq / 2
                    dFdhh[j, i] = dFdhh[i, j]

            # add hyperpriors
            # ------------------------------------------------------------------
            d = h - hE
            dFdh = dFdh - ihC @ d
            dFdhh = dFdhh - ihC
            Ch = spm_inv(-dFdhh.real)

            # update ReML estimate
            # ------------------------------------------------------------------
            dh = spm_dx(dFdhh, dFdh, [4])
            dh = np.minimum(np.maximum(dh, -1), 1)
            h = h + dh

            # convergence
            # ------------------------------------------------------------------
            dF = dFdh.T @ dh
            if dF < 1e-2:
                break

        # E-Step with Levenberg-Marquardt regularization
        # ======================================================================

        # objective function: F(p) = log evidence - divergence
        # ----------------------------------------------------------------------
        L = np.empty(3)  # preallocate
        L[0] = spm_logdet(iS) * nq / 2 - (e.T @ iS @ e).real / 2 - ny * np.log(8 * np.arctan(1)) / 2
        L[1] = spm_logdet(ipC @ Cp) / 2 - p.T @ ipC @ p / 2
        L[2] = spm_logdet(ihC @ Ch) / 2 - d.T @ ihC @ d / 2
        F = np.sum(L)

        # record increases and reference log-evidence for reporting
        # ----------------------------------------------------------------------
        if F0 is not None:
            if not M['noprint']:
                print(' actual: %.3e (%.2f sec)' % ((F - C['F']), time.time() - tStart))
        else:
            F0 = F

        # if F has increased, update gradients and curvatures for E-Step
        # ----------------------------------------------------------------------
        if F > C['F'] or k < 2:

            # accept current estimates
            # ------------------------------------------------------------------
            C['p'] = p
            C['h'] = h
            C['F'] = F
            C['L'] = L
            C['Cp'] = Cp

            # E-Step: Conditional update of gradients and curvature
            # ------------------------------------------------------------------
            dFdp = - (J.T @ iS @ e).real - ipC @ p
            dFdpp = - (J.T @ iS @ J).real - ipC

            # decrease regularization
            # ------------------------------------------------------------------
            v = np.minimum(v + 1 / 2, 4)
            msg = 'EM:(+)'

        else:

            # reset expansion point
            # ------------------------------------------------------------------
            p = C['p']
            h = C['h']
            Cp = C['Cp']

            # and increase regularization
            # ------------------------------------------------------------------
            v = np.minimum(v - 2, -4)
            msg = 'EM:(-)'

        # E-Step: update
        # ======================================================================
        dp = spm_dx(dFdpp, dFdp, [v])
        p = p + dp
        Ep = spm_unvec(spm_vec(pE) + V @ p[ip], pE)

        # Graphics
        # ======================================================================
        # TODO: graphics, maybe...

        # convergence
        # ----------------------------------------------------------------------
        dF = dFdp.T @ dp

        if not M['noprint']:
            print('%-6s: %i %6s %-6.3e %6s %.3e ' % (msg, k, 'F:', C['F'] - F0, 'dF predicted:', dF), end='', flush=True)

        criterion = np.hstack((dF.item() < 1e-1, criterion[:-1]))
        if np.all(criterion):
            if not M['noprint']:
                print(' convergence')
            break

    # TODO: graphics, maybe, focusing the figure with Fsi

    # outputs
    # --------------------------------------------------------------------------

    Ep = spm_unvec(spm_vec(pE) + V @ C['p'][ip], pE)
    Cp = V @ C['Cp'][np.ix_(ip, ip)] @ V.T
    Eh = C['h']
    F = C['F']
    L = C['L']

    return Ep, Cp, Eh, F, L, dFdp, dFdpp



def spm_inv(A, TOL=None):
    """
    inverse for ill-conditioned matrices
    FORMAT X = spm_inv(A,TOL)

    A   - matrix
    X   - inverse

    TOL - tolerance: default = max(eps(norm(A,'inf'))*max(m,n),exp(-32))

    This routine simply adds a small diagonal matrix to A and calls inv.m
    _________________________________________________________________________
    Copyright (C) 2008 Wellcome Trust Centre for Neuroimaging

    Karl Friston
    $Id: spm_inv.m 7143 2017-07-29 18:50:38Z karl $
    """
    # check A
    # --------------------------------------------------------------------------
    m, n = np.shape(np.atleast_2d(A))
    if A is None:
        X = np.zeros(n, m)
        return X

    # tolerance
    # --------------------------------------------------------------------------
    if TOL is None:
        TOL = max(np.spacing(maxnorm(A)) * max(m, n), np.exp(-32))

    # inverse
    # matlab: X = inv(A + speye(m,n)*TOL)
    X = np.linalg.inv(A + np.eye(m, n) * TOL)

    return X


def spm_diag(v, k=0):
    """
    Diagonal matrices and diagonals of a matrix

    Like numpy.diag, but with special handling of lists and object arrays.

    Based on numpy.diag code, but if output has dtype=object,
    fill it with None instead of zeros

    Attempts to emulate spm_diag behavior
    """
    if isinstance(v, (list, tuple)):
        # needed because numpy.diag gives error with lists
        # where each element has the same size
        # eg: np.diag([eye(2), eye(2)]) raises error
        #     np.diag([eye(2), eye(3)]) works
        vv = np.empty(len(v), dtype='O')
        vv[:] = v
        v = vv
    if isobjectarray(v):
        pass
    else:
        v = np.asanyarray(v)
    s = v.shape
    if len(s) == 1:
        n = s[0]+abs(k)
        if v.dtype == object:
            res = np.full((n,n), None)
        else:
            res = np.zeros((n, n), v.dtype)
        if k >= 0:
            i = k
        else:
            i = (-k) * n
        res[:n-k].flat[i::n+1] = v
        return res
    elif len(s) == 2:
        return np.diagonal(v, k)
    else:
        raise ValueError("Input must be 1- or 2-d.")



def spm_bireduce(M, P, nout=2):
    """
    reduction of a fully nonlinear MIMO system to Bilinear form
    FORMAT [M0,M1,L1,L2] = spm_bireduce(M,P);

    M   - model specification structure
    Required fields:
      M.f   - dx/dt    = f(x,u,P,M)                 {function string or m-file}
      M.g   - y(t)     = g(x,u,P,M)                 {function string or m-file}
      M.bi  - bilinear form [M0,M1,L1,L2] = bi(M,P) {function string or m-file}
      M.m   - m inputs
      M.n   - n states
      M.l   - l outputs
      M.x   - (n x 1) = x(0) = expansion point: defaults to x = 0;
      M.u   - (m x 1) = u    = expansion point: defaults to u = 0;

      M.D   - delay operator df/dx -> D*df/dx [optional]

    P   - model parameters

    A Bilinear approximation is returned where the states are

           q(t) = [1; x(t) - x(0)]

    __________________________________________________________________________
    Returns Matrix operators for the Bilinear approximation to the MIMO
    system described by

          dx/dt = f(x,u,P)
           y(t) = g(x,u,P)

    evaluated at x(0) = x and u = 0

          dq/dt = M0*q + u(1)*M1{1}*q + u(2)*M1{2}*q + ....
           y(i) = L1(i,:)*q + q'*L2{i}*q/2;

    -------------------------------------------------------------------------
    Copyright (C) 2008 Wellcome Trust Centre for Neuroimaging

    Karl Friston
    $Id: spm_bireduce.m 6856 2016-08-10 17:55:05Z karl $
    """

    # set up
    # ==========================================================================

    # create inline functions
    # --------------------------------------------------------------------------
    # TODO? try catch?
    funx = spm_funcheck(M['f'])

    # expansion point
    # --------------------------------------------------------------------------
    x = spm_vec(M['x'])
    if 'u' in M:
        u = spm_vec(M['u'])
    else:
        u = np.zeros((M['m'], 1))  # sparse(M.m,1)

    # Partial derivatives for 1st order Bilinear operators
    # ==========================================================================

    # f(x(0),0) and derivatives
    # --------------------------------------------------------------------------

    # TODO
    # if all(isfield(M,{'dfdxu','dfdx','dfdu','f0'})):
    if False:
        dfdxu = M['dfdxu']
        dfdx = M['dfdx']
        dfdu = M['dfdu']
        f0 = M['f0']
    else:
        # print('line 2649 spm_diff inputs:  funx = {}'.format(funx))
        # print('line 2649 spm_diff inputs:  funx, M[x], u, P, M, [0, 1] with P = {}'.format(P))
        # print('                                        shape(u) = {}'.format(np.shape(u)))
        dfdxu, dfdx, *_ = spm_diff(funx, M['x'], u, P, M, np.array([0, 1]))

        # print('line 2653 spm_diff inputs:  funx = {}'.format(funx))
        # print('line 2653 spm_diff inputs:  funx, M[x], u, P, M, 1 and P = {}'.format(np.shape(P)))
        dfdu, f0, *_ = spm_diff(funx, M['x'], u, P, M, 1)
    f0 = spm_vec(f0)
    m = len(dfdxu)  # m inputs # matlab: length
    n = max(f0.shape)  # n states  # matlab: length

    # print('size of f0 =  {}'.format(np.shape(f0)))

    # delay operator
    # --------------------------------------------------------------------------
    # TODO
    # if 'D' in M and D is not None and D.ndim > ...

    # Bilinear operators
    # ==========================================================================

    # Bilinear operator - M0
    # --------------------------------------------------------------------------
    # M0 = spm_cat(np.array([[0, None],
    #                     [(f0 - dfdx @ x), dfdx]]))

    # print('np.array([0, []]) = {}'.format(np.array([0, []])))
    # print('(f0 - dfdx @ x) = {}'.format((f0 - dfdx @ x)))
    # print('dfdx = {}'.format(np.array(dfdx)))
    M0 = spm_cat(np.array([[0, None],
                        [(f0 - dfdx @ x), dfdx]], dtype =object))

    # Bilinear operator - M1 = dM0/du
    # --------------------------------------------------------------------------
    # M1 = full((m, 1), None)  # matlab: cell(m,1);
    M1 = [None] * m
    for i in range(m):
        M1[i] = spm_cat(
            np.array([[0, None],
                   [(dfdu[:, [i]] - dfdxu[i] @ x), dfdxu[i]]], dtype =object))

    if nout < 3:
        return M0, M1

    # Output operators
    # ==========================================================================

    # add observer if not specified
    # --------------------------------------------------------------------------
    if 'g' in M:
        fung = spm_funcheck(M['g'])  # matlab: fcnchk(M.g,'x','u','P','M')
    else:
        M['g'] = 'lambda x, u, P, M: spm_vec(x)'
        M['l'] = n
        fung = spm_funcheck(M['g'])  # matlab: fcnchk(M.g,'x','u','P','M')

    # g(x(0),0)
    # --------------------------------------------------------------------------
    # print('line 2699 spm_diff inputs:  fung = {}'.format(fung))
    # print('line 2699 spm_diff inputs:  fung, M[x], u, P, M, 0 and P = {}'.format(np.shape(P)))

    dgdx, g0 = spm_diff(fung, M['x'], u, P, M, 0)
    g0 = spm_vec(g0)
    l = max(g0.shape)

    # Output matrices - L1
    # --------------------------------------------------------------------------
    # TODO: improve spm_cat so it works with a simple list like this:
    # [spm_vec(g0) - dgdx @ x, dgdx]
    L1 = np.full((1, 2), None)
    L1[0] = [spm_vec(g0) - dgdx @ x, dgdx]
    L1 = spm_cat(L1)

    if nout < 4:
        return M0, M1, L1

    # Output matrices - L2
    # --------------------------------------------------------------------------
    # print('line 2718 spm_diff inputs:  fung = {}'.format(fung))
    # print('line 2718 spm_diff inputs:  fung, M[x], u, P, M, [0, 0], nocat and P = {}'.format(np.shape(P)))

    # write temp data
    # tempdataname = r'C:\Users\16135\PycharmProjects\pantheon\venv\test_functions\debug_data.npy'
    # data = {'fung':fung, 'M':M, 'u':u, 'P':P, 'n':n, 'l':l, 'M1':M1}
    # np.save(tempdataname, data)
    # print('saved data to {}'.format(tempdataname))

    dgdxx, *_ = spm_diff(fung, M['x'], u, P, M, [0, 0], 'nocat')
    D = [None] * l  # full((l, n, dgdxx[0].shape[1])  # preallocate

    # print('size of D is {}'.format(np.shape(D)))
    # print('size of dgdxx is {}'.format(np.shape(dgdxx)))
    # print('l = {}'.format(l))
    # print('n = {}'.format(n))
    # print('dgdxx[0][0].size = {}'.format(dgdxx[0][0].size))
    for i in range(l):
        D[i] = np.zeros((n, dgdxx[0][0].size))
        for j in range(n):
            D[i][j, :] = dgdxx[j][i, :]

    # print('size of D is {}'.format(np.shape(D)))
    L2 = [None] * l
    for i in range(l):
        L2[i] = spm_cat(spm_diag([0, D[i]]))

    return M0, M1, L1, L2


# spm_Ce requires integer input array
def spm_Ce(t, v=None, a=None):
    """
    Error covariance constraints (for serially correlated data)
    FORMAT [C] = spm_Ce(v,a)
    FORMAT [C] = spm_Ce('ar',v,a)
    v  - (1 x n) v(i) = number of observations for i-th block
    a  - AR coefficient expansion point  [Default: a = []]

    a  = [] (default) - block diagonal identity matrices specified by v:

      C{i}  = blkdiag( zeros(v(1),v(1)),...,AR(0),...,zeros(v(end),v(end)))
      AR(0) = eye(v(i),v(i))

    otherwise:

      C{i}     = AR(a) - a*dAR(a)/da;
      C{i + 1} = AR(a) + a*dAR(a)/da;

    FORMAT [C] = spm_Ce('fast',v,tr)
    v  - (1 x n) v(i) = number of observations for i-th block
    tr - repetition time

    See also: spm_Q.m
    _________________________________________________________________________
    Copyright (C) 2000-2017 Wellcome Trust Centre for Neuroimaging

    Karl Friston
    $Id: spm_Ce.m 7203 2017-11-08 12:49:15Z guillaume $
    """

    # Defaults (and backward compatibility with spm_Ce(v,a) == spm_Ce('ar',v,a))
    # --------------------------------------------------------------------------
    if not isinstance(t, str):
        if v is not None:
            a = v
        v = t
        t = 'ar'

    if a is not None:
        a = np.atleast_1d(a)

    # Error covariance constraints
    # --------------------------------------------------------------------------
    if t == 'ar':

        # Create block diagonal components
        # ------------------------------------------------------------------
        C = []
        l = np.size(v)
        n = np.sum(v)
        k = 0
        if l > 1:
            for i in range(l):
                dCda = spm_Ce(v[i], a)
                for j in range(len(dCda)):
                    x, y = np.nonzero(dCda[j])
                    q = dCda[j][x, y]
                    x = x + k
                    y = y + k
                    # matlab: C{end + 1} = sparse(x,y,q,n,n);
                    C.append(np.zeros((n, n)))
                    C[-1][x, y] = q
                k = v[i] + k
        else:

            # dCda
            # --------------------------------------------------------------
            if a is not None:
                Q = spm_Q(a, v)
                # print('line 2718 spm_diff inputs:  spm_Q, a, v, 0 and a = {}'.format(np.shape(a)))
                dQda, *_ = spm_diff('spm_Q', a, v, 0)
                A = a
                if np.size(a) == 1:
                    # numpy doesn't allow matmul with scalar
                    A = np.eye(Q.shape[0]) * a
                else:
                    A = a
                C.append(Q - dQda.ravel()[0] @ A)
                C.append(Q + dQda.ravel()[0] @ A)
            else:
                # matlab: speye(v,v)
                C.append(np.eye(v))

    elif t == 'fast':
        dt = a
        C = []
        n = np.sum(v)
        k = 0
        for m in range(np.size(v)):
            T = np.arange(v[m]) * dt
            d = 2 ** np.arange(np.floor(np.log2(dt / 4)), 7)  # log2(64) = 6
            for i in range(min(6, np.size(d))):
                for j in range(3):
                    QQ = scipy.linalg.toeplitz((T ** j) * np.exp(-T / d[i]))
                    x, y = np.nonzero(QQ)
                    q = QQ[x, y]
                    x = x + k
                    y = y + k
                    # matlab: C{end + 1} = sparse(x,y,q,n,n);
                    C.append(np.zeros((n, n)))
                    C[-1][x, y] = q
            k = k + v[m]
    else:
        raise Exception('Unknown error covariance constraints.')

    return C


def spm_dctmtx(N, K=None, n=None, f=None):
    """
    Create basis functions for Discrete Cosine Transform
    FORMAT C = spm_dctmtx(N)
    FORMAT C = spm_dctmtx(N,K)
    FORMAT C = spm_dctmtx(N,K,n)
    FORMAT D = spm_dctmtx(N,K,'diff')
    FORMAT D = spm_dctmtx(N,K,n,'diff')

    N        - dimension
    K        - order
    n        - optional points to sample

    C        - DCT matrix or its derivative
    _________________________________________________________________________

    spm_dctmtx creates a matrix for the first few basis functions of a one
    dimensional discrete cosine transform.
    With the 'diff' argument, spm_dctmtx produces the derivatives of the DCT.

    Reference:
    Fundamentals of Digital Image Processing (p 150-154). Anil K. Jain, 1989.
    _________________________________________________________________________
    Copyright (C) 1996-2015 Wellcome Trust Centre for Neuroimaging

    John Ashburner
    $Id: spm_dctmtx.m 6416 2015-04-21 15:34:10Z guillaume $
    """

    d = 0

    if K is None:  # nargin == 1
        K = N

    if n is None:  # nargin < 3
        n = np.arange(0, N)  # matlab: (0:(N-1))'
    elif f is None:  # nargin == 3
        if n == 'diff':
            d = 1
            n = np.arange(0, N)  # matlab: (0:(N-1))'
        elif n == 'diff2':
            d = 2
            n = np.arange(0, N)  # matlab: (0:(N-1))'
        else:
            n = n.ravel(order='F')
    else:  # nargin == 4
        n = n.ravel(order='F')
        if f == 'diff':
            d = 1
        elif f == 'diff2':
            d = 2
        else:
            raise Exception('Incorrect Usage.')

    C = np.zeros((n.shape[0], K))
    if d == 0:
        C[:, 0] = np.ones((n.shape[0])) / sqrt(N)
        for k in range(2, K + 1):
            C[:, k - 1] = sqrt(2 / N) * cos(pi * (2 * n + 1) * (k - 1) / (2 * N))
    elif d == 1:
        for k in range(2, K + 1):
            C[:, k - 1] =  \
                -2 ** (1 / 2)  \
                * (1 / N) ** (1 / 2)  \
                * sin(1 / 2 * pi
                      * (2 * n * k - 2 * n + k - 1) / N)  \
                * pi * (k - 1) / N
    elif d == 2:
        for k in range(2, K + 1):
            C[:, k - 1] =  \
                -2 ** (1 / 2)  \
                * (1 / N) ** (1 / 2)  \
                * cos(1 / 2 * pi
                      * (2 * n + 1) * (k - 1) / N)  \
                * pi ** 2  \
                * (k - 1) ** 2 / N ** 2
    else:
        raise Exception('Incorrect usage.')

    return C


def spm_cat(x, d=None):
    """
    Convert a cell array into a matrix - a compiled routine
    FORMAT [x] = spm_cat(x,d)
    x - cell array
    d - dimension over which to concatenate [default - both]
   __________________________________________________________________________
    Empty array elements are replaced by sparse zero partitions and single 0
    entries are expanded to conform to the non-empty non zero elements.

    e.g.:
    > x       = spm_cat({eye(2) []; 0 [1 1; 1 1]})
    > full(x) =

        1     0     0     0
        0     1     0     0
        0     0     1     1
        0     0     1     1

    If called with a dimension argument, a cell array is returned.
   __________________________________________________________________________
    Copyright (C) 2005-2013 Wellcome Trust Centre for Neuroimaging

    Karl Friston
    $Id: spm_cat.m 5731 2013-11-04 18:11:44Z guillaume $
    """

    xx = copy.deepcopy(x)
    # check x is not already a matrix
    # --------------------------------------------------------------------------
    if isobjectarray(xx):
        xx = np.atleast_2d(xx)
        [n, m] = np.shape(xx)
    elif isinstance(xx, (list, tuple)):
        if isinstance(xx[0], (list, tuple)) and len(xx[0]) > 0:
            pass
        else:
            xx = [xx]
    else:
        return xx

    # if concatenation over a specific dimension
    # --------------------------------------------------------------------------
    [n, m] = np.shape(xx)[0:2]
    if d is not None:

        # concatenate over first dimension
        # ----------------------------------------------------------------------
        if d == 0:
            y = full((1, m), None)
            for i in range(m):
                y[i] = spm_cat(xx[:], i)

        # concatenate over second
        # ----------------------------------------------------------------------
        elif d == 2:
            y = full((n, 1))
            for i in range(n):
                y[i] = spm_cat(xx[i, :])

        # only viable for 2-D arrays
        # ----------------------------------------------------------------------
        else:
            raise Exception('unknown option')

        return y

    # find dimensions to fill in empty partitions
    # --------------------------------------------------------------------------
    I = np.zeros((n, m), dtype=int)
    J = np.zeros((n, m), dtype=int)
    for i in range(n):
        for j in range(m):
            xij = xx[i][j]
            if isobjectarray(xij):
                xij = spm_cat(xij)
                xx[i][j] = xij
            if xij is None  \
               or (isinstance(xij, (tuple, list)) and len(xij) == 0):
                u = v = 0
            elif np.isscalar(xij):
                u = v = 1
            elif xij.ndim == 1:
                xij = xij.reshape(-1, 1)
                xx[i][j] = xij
                [u, v] = xij.shape
            else:
                [u, v] = xij.shape
            I[i, j] = u
            J[i, j] = v

    I = np.max(I, axis=1)
    J = np.max(J, axis=0)

    # sparse and empty partitions
    # --------------------------------------------------------------------------
    # [n, m] = shape(x)
    for i in range(n):
        for j in range(m):
            # if isempty(x[i][j]) | (x[i][j] == 0):
            if isempty(xx[i][j]):
                xx[i][j] = np.zeros((I[i], J[j]))  # matlab: sparse
            if np.ndim(xx[i][j]) == 0:
                xx[i][j] = np.atleast_2d(xx[i][j])

    # concatenate
    y = np.full(n, None)
    # print('n = {}'.format(n))
    for i in range(n):
        # print('x[{}][:] = {}'.format(i,x[i][:]))
        y[i] = np.concatenate(xx[i][:], axis=1)

    xx = np.concatenate(y)

    return xx


# [K0,K1,K2,H1] = spm_kernels(varargin)
def spm_kernels(*args, nout=1):
    """
    returns global Volterra kernels for a MIMO Bilinear system
    FORMAT [K0,K1,K2] = spm_kernels(M,P,N,dt)            - output kernels
    FORMAT [K0,K1,K2] = spm_kernels(M0,M1,N,dt)          - state  kernels
    FORMAT [K0,K1,K2] = spm_kernels(M0,M1,L1,N,dt)       - output kernels (1st)
    FORMAT [K0,K1,K2] = spm_kernels(M0,M1,L1,L2,N,dt)    - output kernels (2nd)

    M,P   - model structure and parameters;
            or its bilinear reduction:

    M0    - (n x n)     df(q(0),0)/dq                    - n states
    M1    - {m}(n x n)  d2f(q(0),0)/dqdu                 - m inputs
    L1    - (l x n)     dldq                             - l outputs
    L2    - {m}(n x n)  dl2dqq

    N     - kernel depth       {intervals}
    dt    - interval           {seconds}

    Volterra kernels:
    --------------------------------------------------------------------------
    K0    - (1 x l)             = K0(t)         = y(t)
    K1    - (N x l x m)         = K1i(t,s1)     = dy(t)/dui(t - s1)
    K2    - (N x N x l x m x m) = K2ij(t,s1,s2) = d2y(t)/dui(t - s1)duj(t - s2)

    __________________________________________________________________________
    Returns Volterra kernels for bilinear systems of the form

            dq/dt   = f(q,u) = M0*q + M1{1}*q*u1 + ... M1{m}*q*um
               y(i) = L1(i,:)*q + q'*L2{i}*q

    where q = [1 x(t)] are the states augmented with a constant term

    _________________________________________________________________________
    Copyright (C) 2008 Wellcome Trust Centre for Neuroimaging

    Karl Friston
    $Id: spm_kernels.m 6937 2016-11-20 12:30:40Z karl $
    """

    # assign inputs
    # --------------------------------------------------------------------------
    if len(args) == 4:
        M0 = args[0]
        M1 = args[1]
        N = args[2]
        dt = args[3]

    elif len(args) == 5:
        M0 = args[0]
        M1 = args[1]
        L1 = args[2]
        N = args[3]
        dt = args[4]

    elif len(args) == 6:
        M0 = args[0]
        M1 = args[1]
        L1 = args[2]
        L2 = args[3]
        N = args[4]
        dt = args[5]

    # bilinear reduction if necessary
    # --------------------------------------------------------------------------
    if hasattr(M0, '__dict__'):  # matlab: isstruct
        M0, M1, L1, L2 = spm_bireduce(M0, M1)

    # Volterra kernels for bilinear systems
    # ==========================================================================

    # make states the outputs (i.e. remove constant) if L1 is not specified
    # --------------------------------------------------------------------------
    try:
        L1
    except:
        L1 = np.eye(M0.shape)  # matlab: speye
        L1 = L1[1:, :]
    try:
        L2
    except:
        L2 = []

    # parameters
    # --------------------------------------------------------------------------
    N = int(N)  # kernel depth
    n = M0.shape[0]  # state variables
    m = len(M1)  # inputs
    l = L1.shape[0]  # outputs
    H1 = np.zeros((N, n, m))
    # K1 and K2 preallocation further down
    M0 = dense(M0)  # matlab: full(M0)

    # pre-compute matrix exponentials
    # --------------------------------------------------------------------------
    e1 = scipy.linalg.expm(dt * M0)
    e2 = scipy.linalg.expm(-dt * M0)
    M = np.full((N, m), None)  # preallocate
    for p in range(m):
        M[0, p] = e1 @ M1[p] @ e2
    ei = e1
    for i in range(1, N):
        ei = e1 * ei
        for p in range(m):
            M[i, p] = e1 @ M[i - 1, p] @ e2

    result = []

    # 0th order kernel
    # --------------------------------------------------------------------------
    if nout > 0:
        X0 = np.zeros((n, 1))  # matlab: sparse(1, 1, 1, n, 1)
        X0[0, 0] = 1
        H0 = ei @ X0
        K0 = L1 @ H0
        result.append(K0)

    # 1st order kernel
    # --------------------------------------------------------------------------
    if nout > 1:
        K1 = np.zeros((N, l, m))
        for p in range(m):
            for i in range(N):
                H1[i, :, p] = np.ravel(M[i, p] @ H0)
                K1[i, :, p] = np.ravel(H1[i, :, p]  @  L1.T)
        result.append(K1)

    # 2nd order kernels
    # --------------------------------------------------------------------------
    if nout > 2:
        K2 = np.zeros((N, N, l, m, m))
        for p in range(m):
            for q in range(m):
                for j in range(N):
                    H = L1 @ M[j, q] @ H1[j:N, :, p].T
                    K2[j, j:N, :, q, p] = H.T
                    K2[j:N, j, :, p, q] = H.T

        if L2 is None:  # matlab; isempty(L2)
            result.append(K2)
            return result

    # add output nonlinearity
    # ----------------------------------------------------------------------
        for i in range(m):
            for j in range(m):
                for p in range(l):
                    K2[:, :, p, i, j] = K2[:, :, p, i, j] + H1[:, :, i] @ L2[p] @ H1[:, :, j].T
        result.append(K2)

    return result


def spm_Q(a, n, q=False):
    """
    returns an (n x n) (inverse) autocorrelation matrix for an AR(p) process
    FORMAT [Q] = spm_Q(a,n,q)

    a  - vector of (p) AR coefficients
    n  - size of Q
    q  - switch to return inverse autocorrelation or precision [default q = 0]
    _________________________________________________________________________
    spm_Q uses a Yule-Walker device to compute K where:

    y = K*z

    such that y is an AR(p) process generated from an i.i.d innovation
    z.  This means

    cov(y) = <K*z*z'*K> = K*K'

    If called with q ~= 0, a first order process is assumed when evaluating
    the precision (inverse covariance) matrix; i.e., a = a(1)
    _________________________________________________________________________
    Copyright (C) 2008 Wellcome Trust Centre for Neuroimaging

    Karl Friston
    $Id: spm_Q.m 5838 2014-01-18 18:40:37Z karl $
    """

    if q:
        # compute P (precision)
        # ----------------------------------------------------------------------
        A = np.hstack((-a[0], 1 + a[0]**2, -a[0]))
        # matlab: spdiags(...)
        Q = np.diags(np.ones((n, 1)) * A, np.arange(-1, 2), n, n)
    else:
        p = np.size(a)
        A = np.hstack((1, -a.ravel()))  # matlab: [1 -a(:)']
        # matlab: spdiags(...)
        P = np.diags(np.ones((n, 1)) * A, - np.arange(p + 1), n, n)
        K = np.linalg.inv(P)
        K = K * (np.abs(K) > 1e-4)
        Q = K @ K.T
        Q = scipy.linalg.toeplitz(Q[:, 0])
    return Q



# Just adapt scipy norm.cdf
def spm_Ncdf(x, u=0, V=1):
    return scipy.stats.norm.cdf(x, u, np.sqrt(V))



def spm_data_id(*X):
    """
    generates a specific real number in a deterministic way
    from any data structure
    FORMAT ID = spm_data_id(X);
    X  - numeric, character, cell or stucture array[s]
    ID - specific ID
    _________________________________________________________________________
    Copyright (C) 2009 Wellcome Trust Centre for Neuroimaging

    Vladimir Litvak (based on Karl's spm_vec)
    $Id: spm_data_id.m 6712 2016-02-04 15:12:25Z peter $
    """

    if len(X) == 1:
        X = X[0]

    ID = 0

    if isinstance(X, str):
        pass
    elif isinstance(X, float):
        return X
    elif isinstance(X, int):
        return float(X)
    elif isnumericarray(X):
        Y = X.astype(float)
        ID = np.sum(np.abs(Y[np.isfinite(Y)]))
    elif isinstance(X, dict) or hasattr(X, '__dict__'):
        if hasattr(X, '__dict__'):
            X = X.__dict__
        for key in sorted(X.keys()):
            ID = ID + spm_data_id(X[key])
    elif isinstance(X, (tuple, list)):
        for item in X:
            ID = ID + spm_data_id(item)
    elif isobjectarray(X):
        for item in np.nditer(X):
            ID = ID + spm_data_id(item)

    if ID > 0:
        ID = 10 ** - (np.floor(np.log10(ID)) - 2) * ID

    return ID


def spm_funcheck(f):
    """
    Convert strings and inline objects to function handles
    FORMAT [h] = spm_funcheck(f)

    f   - filename, character expression or inline function
    h   - corresponding function handle
    _________________________________________________________________________
    Copyright (C) 2013 Wellcome Trust Centre for Neuroimaging

    Karl Friston
    $Id: spm_funcheck.m 6481 2015-06-16 17:01:47Z karl $
    """
    h = None

    # -Create function handle
    # ==========================================================================

    # if f is already a function handle
    # --------------------------------------------------------------------------
    if callable(f):
        h = f

    # if f is filename or expression
    # --------------------------------------------------------------------------
    elif isinstance(f, str):
        h = eval(f)

    # if f is an inline object
    # --------------------------------------------------------------------------
    #
    # TODO...?

    return h


def spm_dcm_evidence(DCM):
    """
    Compute evidence of DCM model
    FORMAT evidence = spm_dcm_evidence(DCM)

    DCM       - DCM data structure

    evidence  - structure with the following fields
      .region_cost(i)  - The cost of prediction errors in region i
      .bic_penalty     - Bayesian information criterion penalty
      .bic_overall     - The overall BIC value
      .aic_penalty     - Akaike's information criterion penalty
      .aic_overall     - The overall AIC value

    All of the above are in units of NATS (not bits).
    _________________________________________________________________________
    Copyright (C) 2008 Wellcome Trust Centre for Neuroimaging

    Will Penny
    $Id: spm_dcm_evidence.m 6856 2016-08-10 17:55:05Z karl $
    """

    evidence = {}

    # Only look at those parameters with non-zero posterior covariance
    # --------------------------------------------------------------------------
    v = DCM['v']  # number of samples
    n = DCM['n']  # number of regions
    wsel = np.nonzero(np.diag(DCM['Cp']))[0]

    # Look at costs of coding prediction errors by region
    # --------------------------------------------------------------------------
    # TODO: test/guess what could go wrong here
    evidence['region_cost'] = np.empty(n)
    for i in range(n):
        try:
            lambda_i = DCM['Ce'][i * v, i * v]  # Ce is error covariance
        except:
            try:
                lambda_i = DCM['Ce'][i]  # Ce is a hyperparameter
            except:
                lambda_i = DCM['Ce']  # Ce is the hyperparameter

        evidence['region_cost'][i] = - 0.5 * v * np.log(lambda_i)  \
                                  - 0.5 * DCM['R'][:, i].T @ ((1 / lambda_i) * np.eye(v)) @ DCM['R'][:, i]

    # Results
    # --------------------------------------------------------------------------
    evidence['aic_penalty'] = np.max(wsel.shape)
    evidence['bic_penalty'] = 0.5 * np.max(wsel.shape) * np.log(v)
    evidence['aic_overall'] = np.sum(evidence['region_cost']) - evidence['aic_penalty']
    evidence['bic_overall'] = np.sum(evidence['region_cost']) - evidence['bic_penalty']

    return evidence


# used for cell subtraction in matlab
def spm_dfdx(f, f0, dx):
    if isinstance(f, (tuple, list)) or isobjectarray(f):
        dfdx = copy.copy(f)
        for i in range(np.size(f)):
            dfdx[i] = spm_dfdx(f[i], f0[i], dx)
    # elif matlab struct
    else:
        dfdx = (f - f0) / dx
    return dfdx


def spm_dfdx_cat(J):
    # concatenate into a matrix
    J0 = J.ravel()[0]
    if isvector(J0):
        # assume 1d arrays are column vectors
        if J0.ndim == 1 or (J0.ndim > 1 and J0.shape[1] == 1):
            return spm_cat(J)
        else:
            return spm_cat(J.T).T
    else:
        return J


def spm_diff(*args):
    """
    matrix high-order numerical differentiation
    FORMAT [dfdx] = spm_diff(f,x,...,n)
    FORMAT [dfdx] = spm_diff(f,x,...,n,V)
    FORMAT [dfdx] = spm_diff(f,x,...,n,'q')

    f      - [inline] function f(x{1},...)
    x      - input argument[s]
    n      - arguments to differentiate w.r.t.

    V      - cell array of matrices that allow for differentiation w.r.t.
    to a linear transformation of the parameters: i.e., returns

    df/dy{i};    x = V{i}y{i};    V = dx(i)/dy(i)

    q      - (char) flag to preclude default concatenation of dfdx

    dfdx          - df/dx{i}                     ; n =  i
    dfdx{p}...{q} - df/dx{i}dx{j}(q)...dx{k}(p)  ; n = [i j ... k]


    This routine has the same functionality as spm_ddiff, however it
    uses one sample point to approximate gradients with numerical (finite)
    differences:

    dfdx  = (f(x + dx)- f(x))/dx
    _________________________________________________________________________
    Copyright (C) 2008 Wellcome Trust Centre for Neuroimaging

    Karl Friston
    $Id: spm_diff.m 7143 2017-07-29 18:50:38Z karl $
    """

    # IMPORTANT!
    # n are array indexes
    # from matlab to python, n = n - 1

    # step size for numerical derivatives
    # --------------------------------------------------------------------------
    # TODO: check for GLOBAL_DX
    dx = np.exp(-8)

    f = spm_funcheck(args[0])

    # parse input arguments
    # --------------------------------------------------------------------------

    # matlab cell like
    if (isinstance(args[-1], (list, tuple))) | (isobjectarray(args[-1])):
        # x = np.array(args[1:-2])
        x = list(args[1:-2])
        n = np.atleast_1d(np.array(args[-2]))
        V = args[-1]
        # increase list V beforehand
        # matlab version does it dynamically
        if len(V) < len(x):
            V = V + ([None] * (len(x) - len(V)))
        q = 1
    # numeric
    elif (isinstance(args[-1], (int, float))) | isnumericarray(args[-1]):
        # x = np.array(args[1:-1])
        x = list(args[1:-1])
        n = np.atleast_1d(np.array(args[-1]))
        V = [None] * len(x)
        q = 1
    # characters
    elif isinstance(args[-1], str):
        # x = np.array(args[1:-2])
        # n = np.array(args[-2])
        x = list(args[1:-2])
        n = args[-2]
        # V = [None] * np.size(x)
        V = [None] * len(x)
        q = 0
    else:
        raise Exception('improper call')

    # check transform matrices V = dxdy
    # --------------------------------------------------------------------------
    for i in range(maxshape(x)):
        # no checking if V{i} exists, unlike matlab version
        # V was already extended to len(x) above
        if (V[i] is None) & (np.array(n) == i).any():
            V[i] = np.eye(spm_length(x[i]))  # matlab: speye

    # initialise
    # --------------------------------------------------------------------------
    m = n[-1]
    xm = spm_vec(x[m])
    vmlen = np.atleast_2d(V[m]).shape[1]
    J = np.full((1, vmlen), None)  # matlab: cell

    # proceed to derivatives
    # ==========================================================================

    if np.size(n) == 1:
        # dfdx
        # ----------------------------------------------------------------------
        f0 = f(*x)  # f(x[:])
        for i in range(np.size(J)):
            xi = copy.copy(x)
            # print('xi = {}'.format(xi))
            # print('xi[m] = {}'.format(xi[m]))
            # print('spm_unvec(xm + V[m][:, [i]] * dx, x[m]) = {}'.format(spm_unvec(xm + V[m][:, [i]] * dx, x[m])))
            xi[m] = spm_unvec(xm + V[m][:, [i]] * dx, x[m])
            J[0][i] = spm_dfdx(f(*xi), f0, dx)  # f(xi{:}), ...
            # J[i] = spm_dfdx(f(*xi), f0, dx)  # f(xi{:}), ...

        # return numeric array for first-order derivatives
        # ======================================================================

        # vectorise f
        # ----------------------------------------------------------------------
        f = spm_vec(f0)

        # if there are no arguments to differentiate w.r.t. ...
        # ----------------------------------------------------------------------
        if isempty(xm):  # isempty(xm)
            J = np.zeros((maxshape(f), 0))  # sparse(length(f),0)

        # or there are no arguments to differentiate
        # ----------------------------------------------------------------------
        elif isempty(f):  # isempty(f)
            J = np.zeros((0, maxshape(xm)))  # sparse(0,length(xm))

        # differentiation of a scalar or vector
        # ----------------------------------------------------------------------
        if isnumericarray(f0) and isobjectarray(J) and q:
            J = spm_dfdx_cat(J)

        if isobjectarray(J):
            J = J[0].tolist()

        result = [J, f0]
    else:
        # dfdxdxdx....
        # ----------------------------------------------------------------------
        f0 = np.full((1, np.size(n)), None)
        f0.ravel()[:] = spm_diff(f, *x, n[0:-1], V)
        p = True

        for i in range(np.size(J)):
            xi = copy.copy(x)
            xmi = xm + V[m][:, [i]] * dx
            xi[m] = spm_unvec(xmi, x[m])
            fi = spm_diff(f, *xi, n[0:-1], V)[0]  # spm_diff returns two outputs
            # print('fi = {}'.format(fi))
            J[0][i] = spm_dfdx(fi, f0.ravel()[0], dx)
            p = p & isnumericarray(J[0][i])

        if p and q:
            J = spm_dfdx_cat(J)

        if isobjectarray(J):
            J = J[0].tolist()

        result = [J, *f0.ravel()]  # matlab: [{J} f0]

    return result


def spm_dx(dfdx, f, t=np.inf):
    """
    returns dx(t) = (scipy.linalg.expm(dfdx*t) - I) * LA.inv(dfdx) * f
    FORMAT [dx] = spm_dx(dfdx,f,[t])
    dfdx   = df/dx
    f      = dx/dt
    t      = integration time: (default t = Inf);
             if t is a cell (i.e., {t}) then t is set to:
             exp(t - log(np.diag(-dfdx))

    dx     = x(t) - x(0)
    -------------------------------------------------------------------------
    Integration of a dynamic system using local linearization.  This scheme
    accommodates nonlinearities in the state equation by using a functional of
    f(x) = dx/dt.  This uses the equality

                expm([0   0     ]) = (scipy.linalg.expm(t * dfdx) - I) * LA.inv(dfdx)*f
                     [t*f t*dfdx]

    When t -> Inf this reduces to

                 dx(t) = -LA.inv(dfdx) * f

    These are the solutions to the gradient ascent ODE

               dx/dt   = k*f = k*dfdx*x =>

               dx(t)   = scipy.linalg.expm(t*k*dfdx)*x(0)
                       = scipy.linalg.expm(t * k * dfdx) * LA.inv(dfdx) * f(0) -
                         scipy.linalg.expm(0 * k * dfdx) * LA.inv(dfdx) * f(0)

    When f = dF/dx (and dfdx = dF/dxdx), dx represents the update from a
    Gauss-Newton ascent on F.  This can be regularised by specifying {t}
    A heavy regularization corresponds to t = -4 and a light
    regularization would be t = 4. This version of spm_dx uses an augmented
    system and the Pade approximation to compute requisite matrix
    exponentials

    references:

    Friston K, Mattout J, Trujillo-Barreto N, Ashburner J, Penny W. (2007).
    Variational free energy and the Laplace approximation. NeuroImage.
    34(1):220-34

    Ozaki T (1992) A bridge between nonlinear time-series models and
    nonlinear stochastic dynamical systems: A local linearization approach.
    Statistica Sin. 2:113-135.

    _________________________________________________________________________
    Copyright (C) 2008 Wellcome Trust Centre for Neuroimaging

    Karl Friston
    $Id: spm_dx.m 7144 2017-07-31 13:55:55Z karl $
    """

    # defaults
    # --------------------------------------------------------------------------
    nmax = 512  # threshold for numerical approximation
    xf = copy.copy(f)
    f = spm_vec(f)  # vectorise
    n = np.size(f)  # dimensionality

    # t is a regulariser
    # --------------------------------------------------------------------------
    # matlab: sw  = warning('off','MATLAB:log:logOfZero');
    if isinstance(t, (tuple, list)):

        # relative integration time
        # ----------------------------------------------------------------------
        # matlab: t = t{:}
        t = t[0]
        if np.size(t) == 1:  # scalar
            t = np.exp(t - spm_logdet(dfdx) / n)
        else:
            t = np.exp(t - log(np.diag(-dfdx)))
    # matlab: warning(sw)

    # use a [pseudo]inverse if all t > TOL
    # ==========================================================================
    if np.min(t) > np.exp(16):

        dx = -np.linalg.pinv(dfdx) @ f

    else:

        # ensure t is a scalar or matrix
        # ----------------------------------------------------------------------
        # matlab: if isvector(t), ...
        if (not isinstance(t, (float, int))) and isvector(t):
            t = np.diag(t)

        # augment Jacobian and take matrix exponential
        # ======================================================================
        J = spm_cat(np.array([[0,     None],
                           [t * f, t * dfdx]], dtype = object))

        # solve using matrix expectation
        # ----------------------------------------------------------------------
        if n <= nmax:
            # dx = wrappers.expm_fn(J)
            dx = spm_expm(J)
            dx = dx[:, 0]
        else:
            # matlab: sparse(1,1,1,n + 1,1)
            x = np.zeros(n + 1)
            x[0] = 1
            dx, *_ = expv(1, J, x)

        # recover update
        # ----------------------------------------------------------------------
        dx = dx.ravel()[1:]

    dx = spm_unvec(dx.real, xf)

    return dx


def spm_length(X):
    """
    Length of a vectorised numeric, cell or structure array
    FORMAT [n] = spm_length(X)
    X    - numeric, cell or stucture array[s]
    n    - length(spm_vec(X))

    See spm_vec, spm_unvec
    _________________________________________________________________________

    e.g.:
    spm_length({eye(2) 3}) = 5
    _________________________________________________________________________
    Copyright (C) 2014 Wellcome Trust Centre for Neuroimaging

    Karl Friston
    $Id: spm_length.m 6233 2014-10-12 09:43:50Z karl $
    """
    return spm_vec(X).size


def spm_logdet(C):
    """
    Compute the log of the determinant of positive (semi-)definite matrix C
    FORMAT H = spm_logdet(C)
    H = log(det(C))

    spm_logdet is a computationally efficient operator that can deal with
    full or sparse matrices. For non-positive definite cases, the determinant
    is considered to be the product of the positive singular values.
    _________________________________________________________________________
    Copyright (C) 2008-2013 Wellcome Trust Centre for Neuroimaging

    Karl Friston and Ged Ridgway
    $Id: spm_logdet.m 6321 2015-01-28 14:40:44Z karl $

    Note that whether sparse or full, rank deficient cases are handled in the
    same way as in spm_logdet revision 4068, using svd on a full version of C
    """

    # remove null variances
    # --------------------------------------------------------------------------
    i = np.nonzero(np.diagonal(C))[0]
    C = C[np.ix_(i, i)]
    i, j = np.nonzero(C)
    s = C[i, j]
    if np.any(np.isnan(s)):
        H = nan
        return H

    # TOL = max(size(C)) * eps(max(s)); % as in MATLAB's rank function
    # --------------------------------------------------------------------------
    TOL = 1e-16

    if np.any(i != j):

        # assymetric matrix
        # ------------------------------------------------------------------
        if maxnorm(spm_vec(C - C.T)) > TOL:
            s = np.linalg.svd(dense(C), compute_uv=False)  # matlab: s = svd(full(C))

        else:
            # TODO? handle sparse matrix case

            # non-diagonal full matrix
            # --------------------------------------------------------------
            try:
                R = cholesky(C)
                H = 2 * np.sum(log(np.diag(R)))
            except np.linalg.LinAlgError:
                s = np.linalg.svd(C, compute_uv=False)

    # if still here, singular values in s (diagonal values as a special case)
    # --------------------------------------------------------------------------
    H = np.sum(np.log(s[(s > TOL) & (s < 1 / TOL)]))
    return H




def spm_expm(J, x=None):
    """
    approximate matrix exponential using a Taylor expansion
    FORMAT [y] = spm_expm(J,x)
    FORMAT [y] = spm_expm(J)
    y          = expm(J)*x:
    y          = expm(J);

    This routine covers and extends expm  functionality  by  using  a
    comoutationally  expedient  approximation  that can handle sparse
    matrices when dealing with the special case of expm(J)*x, where x
    is a vector, in an efficient fashion
    _________________________________________________________________________
    Copyright (C) 2008 Wellcome Trust Centre for Neuroimaging

    Karl Friston
    $Id: spm_expm.m 5691 2013-10-11 16:53:00Z karl $
    """

    # expm(J) use Pade approximation
    # ======================================================================

    # ensure norm is < 1/2 by scaling by power of 2
    # ----------------------------------------------------------------------
    I = np.eye(J.shape[0])  # matlab: speye
    e = np.frexp(maxnorm(J))[1]
    s = np.max([0, e + 1])
    J = J / 2**s
    X = J
    c = 1 / 2
    E = I + c * J
    D = I - c * J
    q = 6
    p = True
    for k in range(2, q + 1):
        c = c * (q - k + 1) / (k * (2 * q - k + 1))
        X = J @ X
        cX = c * X
        E = E + cX
        if p:
            D = D + cX
        else:
            D = D - cX
        p = not p

    # E = inv(D)*E
    # --------------------------------------------------------------------------
    E = np.linalg.solve(D, E)

    # Undo scaling by repeated squaring E = E^(2^s)
    # --------------------------------------------------------------------------
    for k in range(s):
        E = E @ E

    # Multiply by x if necessary
    # --------------------------------------------------------------------------
    if x is None:
        return E
    else:
        return E @ x


def spm_phi(x):
    """
    logistic function
    y = 1 / (1 + exp(-x))
    """
    return 1 / (1 + np.exp(-x))


def spm_trace(A, B):
    """
    fast trace for large matrices: C = spm_trace(A,B) = trace(A*B)
    FORMAT [C] = spm_trace(A,B)

    C = spm_trace(A,B) = trace(A*B) = sum(sum(A'.*B));
    _________________________________________________________________________
    Copyright (C) 2008 Wellcome Trust Centre for Neuroimaging

    Karl Friston
    $Id: spm_trace.m 4805 2012-07-26 13:16:18Z karl $

    fast trace for large matrices: C = spm_trace(A,B) = trace(A*B)
    -------------------------------------------------------------------------
    """
    C = np.sum(A.T * B)
    return C


def isempty(x):
    if x is None:
        return True
    if isinstance(x, np.ndarray) and x.size == 0:
        return True
    if isinstance(x, (list, tuple)) and len(x) == 0:
        return True
    return False

def isrealarray(x):
    real_typecodes = ''.join(set(np.typecodes['AllInteger']
                                 + np.typecodes['AllFloat']))

    r = isinstance(x, np.ndarray) and x.dtype.kind in real_typecodes
    return r


def isnumericarray(x):
    numeric_typecodes = ''.join(set(np.typecodes['AllInteger']
                                    + np.typecodes['AllFloat']
                                    + np.typecodes['Complex']))

    r = isinstance(x, np.ndarray) and x.dtype.char in numeric_typecodes
    return r


def isnumericscalar(x):

    # based on numpy.ScalarTypes
    numeric_scalar_types = (
        int,
        float,
        complex,
        int,
        bool,
        bytes,
        np.complex128,
        np.float64,
        np.uint32,
        np.int32,
        np.bytes_,
        np.complex64,
        np.float32,
        np.uint16,
        np.int16,
        np.bool_,
        # np.timedelta64,
        np.float16,
        np.uint8,
        np.int8,
        # np.datetime64,
        np.uint64,
        np.int64,
        np.void,
        np.cdouble,
        np.double,
        np.uint64,
        np.int64,
    )

    r = isinstance(x, numeric_scalar_types)
    return r


def isobjectarray(x):
    r = isinstance(x, np.ndarray) and x.dtype.kind == 'O'
    return r


def issize1(x):
    if isinstance(x, (int, float)):
        return True
    elif isinstance(x, np.ndarray) and x.size == 1:
        return True
    # note: matlab isscalar returns True for single characters
    # elif...
    else:
        return False


def isvector(x):
    r = False
    if isinstance(x, np.ndarray):
        r = np.sum(np.equal(x.shape, 1)) == (x.ndim - 1)
    elif isinstance(x, (float, int)):
        r = True
    elif isinstance(x, (tuple, list)):
        r = len(x) == np.size(x)
    return r



def maxshape(x):
    if isinstance(x, np.ndarray):
        smin = np.min(x.shape)
        if smin == 0:
            # as matlab behavior
            return smin
        else:
            return np.max(x.shape)
    if isinstance(x, (tuple, list)):
        return len(x)
    if isinstance(x, (float, int)):
        return 1
    return 0



def dense(x):
    if sparse.issparse(x):
        return x.toarray()
    else:
        return x


def diags(v, d, m, n):
    """
    Dense matrix version of spdiags
    Based on octave implementation
    Unlike scipy spdiags, arg v has diagonals in column direction
    """
    j, i = np.nonzero(v)
    v = v[j, i]
    if m >= n:
        offset = np.maximum(np.minimum(d, n - m), 0)
    else:
        offset = d
    j = j + offset[i]
    i = j - d[i]
    idx = (i >= 0) & (i < m) & (j >= 0) & (j < n)
    B = np.zeros((m, n), dtype=v.dtype)
    B[i[idx], j[idx]] = v[idx]
    return B


def maxnorm(x):
    """
    About same speed of scipy.linalg.norm(x, inf)
    Works with sparse arrays, unlike scipy version
    """
    if x.ndim == 1:
        return np.max(np.abs(x))
    else:
        return np.max(np.sum(np.abs(x), axis=1))


def sptrace(x):
    """
    Trace function that works with sparse arrays
    """
    return x.diagonal().sum()